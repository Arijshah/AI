"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[898],{7264(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>_,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"physical-ai/vision-language-action-vla/cognitive-planning-with-llms","title":"Cognitive Planning with LLMs Mapped to ROS 2 Actions","description":"Overview","source":"@site/docs/physical-ai/vision-language-action-vla/cognitive-planning-with-llms.md","sourceDirName":"physical-ai/vision-language-action-vla","slug":"/physical-ai/vision-language-action-vla/cognitive-planning-with-llms","permalink":"/AI/docs/physical-ai/vision-language-action-vla/cognitive-planning-with-llms","draft":false,"unlisted":false,"editUrl":"https://github.com/arijh/physical-ai-book/tree/main/packages/create-docusaurus/templates/shared/docs/physical-ai/vision-language-action-vla/cognitive-planning-with-llms.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docs","previous":{"title":"Voice-to-Action using Whisper","permalink":"/AI/docs/physical-ai/vision-language-action-vla/voice-to-action-using-whisper"},"next":{"title":"Capstone Project: Autonomous Humanoid Robot in Simulation","permalink":"/AI/docs/physical-ai/vision-language-action-vla/capstone-project-autonomous-humanoid-robot"}}');var i=t(4848),s=t(8453);const o={sidebar_position:3},r="Cognitive Planning with LLMs Mapped to ROS 2 Actions",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Hands-on Steps",id:"hands-on-steps",level:2},{value:"Step 1: Set up the Cognitive Planning Environment",id:"step-1-set-up-the-cognitive-planning-environment",level:3},{value:"Step 2: Create the Cognitive Planning Node",id:"step-2-create-the-cognitive-planning-node",level:3},{value:"Step 3: Create the LLM Planner Module",id:"step-3-create-the-llm-planner-module",level:3},{value:"Step 4: Create the Task Decomposer",id:"step-4-create-the-task-decomposer",level:3},{value:"Step 5: Create the Action Executor",id:"step-5-create-the-action-executor",level:3}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"cognitive-planning-with-llms-mapped-to-ros-2-actions",children:"Cognitive Planning with LLMs Mapped to ROS 2 Actions"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"This lesson explores how to implement cognitive planning using Large Language Models (LLMs) and map their high-level reasoning to concrete ROS 2 actions. We'll create a cognitive planning system that can interpret complex user requests, break them down into executable steps, and coordinate multiple ROS 2 nodes to accomplish sophisticated tasks. This approach enables robots to perform complex, multi-step operations based on natural language instructions."}),"\n",(0,i.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this lesson, you will:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Understand cognitive planning architectures for robotics"}),"\n",(0,i.jsx)(n.li,{children:"Implement LLM-based task decomposition and planning"}),"\n",(0,i.jsx)(n.li,{children:"Map high-level plans to ROS 2 action sequences"}),"\n",(0,i.jsx)(n.li,{children:"Create a cognitive planning node that coordinates multiple ROS 2 services"}),"\n",(0,i.jsx)(n.li,{children:"Integrate LLM reasoning with robot execution systems"}),"\n",(0,i.jsx)(n.li,{children:"Handle plan failures and replanning scenarios"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"hands-on-steps",children:"Hands-on Steps"}),"\n",(0,i.jsx)(n.h3,{id:"step-1-set-up-the-cognitive-planning-environment",children:"Step 1: Set up the Cognitive Planning Environment"}),"\n",(0,i.jsx)(n.p,{children:"First, let's create the necessary packages and dependencies for our cognitive planning system."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Create the cognitive planning package\ncd ~/ros2_ws/src\nros2 pkg create --dependencies rclpy std_msgs sensor_msgs geometry_msgs action_msgs ros2_actions --node-name cognitive_planner cognitive_planning\n\ncd cognitive_planning\nmkdir -p cognitive_planning/{planning,llm,utils,execution}\n"})}),"\n",(0,i.jsx)(n.p,{children:"Install the required Python dependencies:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install openai anthropic transformers torch ros2_numpy\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-2-create-the-cognitive-planning-node",children:"Step 2: Create the Cognitive Planning Node"}),"\n",(0,i.jsx)(n.p,{children:"Create the main cognitive planning node that will receive high-level goals, use an LLM to decompose them into subtasks, and execute them through ROS 2:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# cognitive_planning/cognitive_planning/cognitive_planner_node.py\nimport rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String, Bool\nfrom cognitive_planning.llm.planner import LLMPlanner\nfrom cognitive_planning.execution.executor import ActionExecutor\nfrom cognitive_planning.planning.task_decomposer import TaskDecomposer\nimport json\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass CognitivePlannerNode(Node):\n    def __init__(self):\n        super().__init__('cognitive_planner')\n\n        # Initialize cognitive planning components\n        self.llm_planner = LLMPlanner()\n        self.task_decomposer = TaskDecomposer()\n        self.action_executor = ActionExecutor(self)\n\n        # Publishers\n        self.plan_status_pub = self.create_publisher(String, 'plan_status', 10)\n        self.execution_feedback_pub = self.create_publisher(String, 'execution_feedback', 10)\n\n        # Subscribers\n        self.goal_sub = self.create_subscription(\n            String,\n            'high_level_goal',\n            self.goal_callback,\n            10\n        )\n\n        self.plan_execution_sub = self.create_subscription(\n            Bool,\n            'execute_plan',\n            self.execute_plan_callback,\n            10\n        )\n\n        # Internal state\n        self.current_plan = None\n        self.plan_lock = asyncio.Lock()\n        self.executor_pool = ThreadPoolExecutor(max_workers=4)\n\n        # Parameters\n        self.declare_parameter('llm_model', 'gpt-4')\n        self.declare_parameter('max_replan_attempts', 3)\n        self.declare_parameter('plan_timeout', 30.0)\n\n        self.get_logger().info('Cognitive Planner Node initialized')\n\n    def goal_callback(self, msg):\n        \"\"\"Handle high-level goals from user or other nodes\"\"\"\n        goal_text = msg.data\n        self.get_logger().info(f'Received high-level goal: {goal_text}')\n\n        # Plan the goal in a separate thread to avoid blocking\n        future = asyncio.run_coroutine_threadsafe(\n            self.plan_goal_async(goal_text),\n            asyncio.get_event_loop()\n        )\n\n    async def plan_goal_async(self, goal_text: str):\n        \"\"\"Asynchronously plan a goal using LLM\"\"\"\n        try:\n            self.get_logger().info(f'Planning goal: {goal_text}')\n\n            # Decompose the goal into subtasks using LLM\n            plan = await self.task_decomposer.decompose_goal(goal_text)\n\n            if plan:\n                self.current_plan = plan\n                self.get_logger().info(f'Generated plan with {len(plan)} steps')\n\n                # Publish plan for review\n                plan_msg = String()\n                plan_msg.data = json.dumps({\n                    'goal': goal_text,\n                    'plan': plan,\n                    'status': 'planned'\n                })\n                self.plan_status_pub.publish(plan_msg)\n\n                # Auto-execute if configured to do so\n                if self.get_parameter('auto_execute').value:\n                    await self.execute_current_plan()\n            else:\n                self.get_logger().error('Failed to generate plan for goal')\n\n        except Exception as e:\n            self.get_logger().error(f'Error planning goal: {str(e)}')\n\n    def execute_plan_callback(self, msg):\n        \"\"\"Execute the current plan if available\"\"\"\n        if msg.data and self.current_plan:\n            future = asyncio.run_coroutine_threadsafe(\n                self.execute_current_plan(),\n                asyncio.get_event_loop()\n            )\n\n    async def execute_current_plan(self):\n        \"\"\"Execute the current plan step by step\"\"\"\n        if not self.current_plan:\n            self.get_logger().warn('No plan to execute')\n            return\n\n        self.get_logger().info('Starting plan execution')\n\n        execution_msg = String()\n        execution_msg.data = json.dumps({\n            'status': 'executing',\n            'plan': self.current_plan\n        })\n        self.execution_feedback_pub.publish(execution_msg)\n\n        # Execute each step in the plan\n        for i, step in enumerate(self.current_plan):\n            self.get_logger().info(f'Executing step {i+1}/{len(self.current_plan)}: {step[\"action\"]}')\n\n            try:\n                # Execute the action\n                success = await self.action_executor.execute_action(step)\n\n                if success:\n                    self.get_logger().info(f'Step {i+1} completed successfully')\n                else:\n                    self.get_logger().error(f'Step {i+1} failed')\n                    # Try to recover or replan\n                    await self.handle_step_failure(i, step)\n                    break\n\n            except Exception as e:\n                self.get_logger().error(f'Step {i+1} execution error: {str(e)}')\n                await self.handle_step_failure(i, step)\n                break\n\n        # Mark plan completion\n        completion_msg = String()\n        completion_msg.data = json.dumps({\n            'status': 'completed',\n            'plan': self.current_plan\n        })\n        self.execution_feedback_pub.publish(completion_msg)\n\n    async def handle_step_failure(self, step_index: int, step: dict):\n        \"\"\"Handle step failure and attempt recovery\"\"\"\n        self.get_logger().warn(f'Handling failure for step {step_index}: {step[\"action\"]}')\n\n        # Publish failure status\n        failure_msg = String()\n        failure_msg.data = json.dumps({\n            'status': 'failed',\n            'failed_step': step_index,\n            'step': step\n        })\n        self.execution_feedback_pub.publish(failure_msg)\n\n        # Attempt recovery based on failure type\n        recovery_type = step.get('recovery', 'none')\n\n        if recovery_type == 'retry':\n            # Retry the failed step\n            success = await self.action_executor.execute_action(step)\n            if success:\n                self.get_logger().info('Recovery successful')\n                return\n\n        elif recovery_type == 'skip':\n            # Skip to next step\n            self.get_logger().info('Skipping failed step')\n            # Continue execution from next step\n            remaining_plan = self.current_plan[step_index + 1:]\n            for j, next_step in enumerate(remaining_plan):\n                success = await self.action_executor.execute_action(next_step)\n                if not success:\n                    self.get_logger().error(f'Step {step_index + 1 + j} also failed')\n                    break\n\n        elif recovery_type == 'replan':\n            # Replan from the current state\n            await self.replan_from_failure(step_index)\n\n        else:\n            # No recovery strategy - plan fails\n            self.get_logger().error('Plan execution failed with no recovery')\n\n    async def replan_from_failure(self, failed_step_index: int):\n        \"\"\"Replan the remaining tasks after a failure\"\"\"\n        self.get_logger().info(f'Replanning from step {failed_step_index}')\n\n        # Get remaining tasks\n        remaining_tasks = self.current_plan[failed_step_index + 1:]\n\n        if not remaining_tasks:\n            self.get_logger().info('No remaining tasks to replan')\n            return\n\n        # Ask LLM to replan based on current state\n        try:\n            replanned_tasks = await self.task_decomposer.replan_remaining_tasks(\n                self.current_plan[:failed_step_index],  # Completed tasks\n                remaining_tasks  # Remaining tasks\n            )\n\n            if replanned_tasks:\n                # Update the plan with replanned tasks\n                self.current_plan = self.current_plan[:failed_step_index] + replanned_tasks\n                self.get_logger().info(f'Replanned with {len(replanned_tasks)} new tasks')\n\n                # Execute the replanned tasks\n                for i, step in enumerate(replanned_tasks):\n                    success = await self.action_executor.execute_action(step)\n                    if not success:\n                        self.get_logger().error(f'Replanned step {i} failed')\n                        break\n            else:\n                self.get_logger().error('Failed to replan remaining tasks')\n\n        except Exception as e:\n            self.get_logger().error(f'Error during replanning: {str(e)}')\n\n    def destroy_node(self):\n        \"\"\"Clean up resources\"\"\"\n        self.executor_pool.shutdown(wait=True)\n        super().destroy_node()\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = CognitivePlannerNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Shutting down Cognitive Planner Node')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-3-create-the-llm-planner-module",children:"Step 3: Create the LLM Planner Module"}),"\n",(0,i.jsx)(n.p,{children:"Now let's create the LLM-based planner that will handle the cognitive reasoning:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# cognitive_planning/cognitive_planning/llm/planner.py\nimport openai\nimport json\nfrom typing import Dict, List, Any, Optional\nimport asyncio\nimport logging\n\nclass LLMPlanner:\n    def __init__(self, model="gpt-4", api_key=None):\n        """\n        Initialize the LLM Planner\n        """\n        self.model = model\n        self.client = openai.OpenAI(api_key=api_key) if api_key else openai.OpenAI()\n        self.logger = logging.getLogger(__name__)\n\n    async def plan_task(self, goal: str, context: Dict[str, Any] = None) -> Optional[List[Dict[str, Any]]]:\n        """\n        Generate a plan for a given goal using LLM\n        """\n        prompt = self._create_planning_prompt(goal, context)\n\n        try:\n            response = await self.client.chat.completions.create(\n                model=self.model,\n                messages=[\n                    {"role": "system", "content": self._get_system_prompt()},\n                    {"role": "user", "content": prompt}\n                ],\n                temperature=0.1,\n                max_tokens=2048,\n                response_format={"type": "json_object"}\n            )\n\n            plan_json = response.choices[0].message.content\n            plan = json.loads(plan_json)\n\n            return plan.get(\'plan\', [])\n\n        except Exception as e:\n            self.logger.error(f"Error generating plan: {str(e)}")\n            return None\n\n    def _create_planning_prompt(self, goal: str, context: Dict[str, Any]) -> str:\n        """\n        Create a structured prompt for task planning\n        """\n        context_str = json.dumps(context, indent=2) if context else "{}"\n\n        prompt = f"""\n        You are a cognitive planning assistant for a humanoid robot. Your task is to decompose high-level goals into executable steps.\n\n        Goal: {goal}\n\n        Context: {context_str}\n\n        Please provide a detailed plan in JSON format with the following structure:\n        {{\n            "plan": [\n                {{\n                    "id": 1,\n                    "action": "action_name",\n                    "description": "Human-readable description of the action",\n                    "parameters": {{"param1": "value1", "param2": "value2"}},\n                    "dependencies": ["action_id"],  # Actions that must be completed before this one\n                    "recovery": "retry|skip|replan|none",  # How to handle failure\n                    "timeout": 30.0  # Timeout in seconds\n                }}\n            ]\n        }}\n\n        Available actions:\n        - navigate_to: Move robot to a specific location\n        - detect_object: Use vision system to detect objects\n        - pick_up: Pick up an object\n        - place: Place an object at a location\n        - speak: Speak a text message\n        - wait: Wait for a condition or time period\n        - call_service: Call a specific ROS 2 service\n\n        Ensure the plan is feasible, safe, and considers the robot\'s capabilities.\n        """\n\n        return prompt\n\n    def _get_system_prompt(self) -> str:\n        """\n        Get the system prompt for the LLM\n        """\n        return """\n        You are a cognitive planning assistant for a humanoid robot. Your role is to decompose complex goals into simple, executable steps that can be performed by a robot system.\n\n        Guidelines:\n        1. Break down complex tasks into simple, atomic actions\n        2. Consider the dependencies between actions\n        3. Account for the robot\'s physical limitations and capabilities\n        4. Include appropriate recovery strategies for each action\n        5. Provide clear, unambiguous instructions\n        6. Ensure the plan is safe and feasible\n\n        Always respond in valid JSON format with the specified structure.\n        """\n\n    async def refine_plan(self, plan: List[Dict[str, Any]], feedback: str) -> Optional[List[Dict[str, Any]]]:\n        """\n        Refine an existing plan based on feedback\n        """\n        prompt = f"""\n        You are refining a robot execution plan based on feedback.\n\n        Original Plan: {json.dumps(plan, indent=2)}\n\n        Feedback: {feedback}\n\n        Please provide an improved plan in the same JSON format, addressing the feedback while maintaining the original goal.\n        """\n\n        try:\n            response = await self.client.chat.completions.create(\n                model=self.model,\n                messages=[\n                    {"role": "system", "content": self._get_system_prompt()},\n                    {"role": "user", "content": prompt}\n                ],\n                temperature=0.1,\n                max_tokens=2048,\n                response_format={"type": "json_object"}\n            )\n\n            plan_json = response.choices[0].message.content\n            refined_plan = json.loads(plan_json)\n\n            return refined_plan.get(\'plan\', [])\n\n        except Exception as e:\n            self.logger.error(f"Error refining plan: {str(e)}")\n            return None\n\n    async def evaluate_plan_feasibility(self, plan: List[Dict[str, Any]], environment_state: Dict[str, Any]) -> Dict[str, Any]:\n        """\n        Evaluate if a plan is feasible given the current environment state\n        """\n        prompt = f"""\n        Evaluate the feasibility of this robot plan given the environment state.\n\n        Plan: {json.dumps(plan, indent=2)}\n\n        Environment State: {json.dumps(environment_state, indent=2)}\n\n        Please respond with a JSON object containing:\n        {{\n            "feasible": true/false,\n            "issues": ["issue1", "issue2", ...],\n            "confidence": 0.0-1.0,\n            "suggestions": ["suggestion1", "suggestion2", ...]\n        }}\n        """\n\n        try:\n            response = await self.client.chat.completions.create(\n                model=self.model,\n                messages=[\n                    {"role": "system", "content": self._get_system_prompt()},\n                    {"role": "user", "content": prompt}\n                ],\n                temperature=0.1,\n                max_tokens=1024,\n                response_format={"type": "json_object"}\n            )\n\n            evaluation = json.loads(response.choices[0].message.content)\n            return evaluation\n\n        except Exception as e:\n            self.logger.error(f"Error evaluating plan feasibility: {str(e)}")\n            return {"feasible": False, "issues": [str(e)], "confidence": 0.0, "suggestions": []}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-4-create-the-task-decomposer",children:"Step 4: Create the Task Decomposer"}),"\n",(0,i.jsx)(n.p,{children:"Now let's create the task decomposer that will handle the cognitive planning process:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# cognitive_planning/cognitive_planning/planning/task_decomposer.py\nimport asyncio\nfrom typing import Dict, List, Any, Optional\nfrom cognitive_planning.llm.planner import LLMPlanner\nimport json\nimport logging\n\nclass TaskDecomposer:\n    def __init__(self):\n        self.llm_planner = LLMPlanner()\n        self.logger = logging.getLogger(__name__)\n\n    async def decompose_goal(self, goal: str) -> Optional[List[Dict[str, Any]]]:\n        """\n        Decompose a high-level goal into executable steps\n        """\n        # Get current environment state (this would come from perception system)\n        environment_state = await self._get_environment_state()\n\n        # Generate plan using LLM\n        plan = await self.llm_planner.plan_task(goal, environment_state)\n\n        if plan:\n            # Validate and refine the plan\n            is_feasible = await self._validate_plan(plan, environment_state)\n            if is_feasible:\n                return plan\n            else:\n                # Try to refine the plan\n                refined_plan = await self._refine_plan_with_feedback(plan, environment_state)\n                if refined_plan:\n                    return refined_plan\n\n        return None\n\n    async def replan_remaining_tasks(self, completed_tasks: List[Dict[str, Any]],\n                                   remaining_tasks: List[Dict[str, Any]]) -> Optional[List[Dict[str, Any]]]:\n        """\n        Replan remaining tasks after a failure, considering completed tasks\n        """\n        environment_state = await self._get_environment_state()\n\n        # Create context about what has been completed\n        context = {\n            "completed_tasks": completed_tasks,\n            "remaining_goals": remaining_tasks,\n            "current_state": environment_state\n        }\n\n        # Generate new plan for remaining tasks\n        prompt = f"""\n        You are replanning robot tasks after a failure. Some tasks have been completed successfully,\n        but there was a failure in the middle of execution.\n\n        Completed Tasks: {json.dumps(completed_tasks, indent=2)}\n        Remaining Goals: {json.dumps(remaining_tasks, indent=2)}\n        Current Environment State: {json.dumps(environment_state, indent=2)}\n\n        Please generate a new plan that continues from the current state to achieve the remaining goals.\n        """\n\n        # This would involve calling the LLM with the specific replanning prompt\n        # For now, we\'ll use a simplified approach\n        new_plan = []\n\n        for task in remaining_tasks:\n            # Adjust parameters based on current state\n            new_task = task.copy()\n            # Add any necessary adjustments based on completed tasks\n            new_plan.append(new_task)\n\n        return new_plan\n\n    async def _get_environment_state(self) -> Dict[str, Any]:\n        """\n        Get the current environment state from perception and other systems\n        """\n        # This would typically query various ROS 2 topics and services\n        # to get the current state of the world\n        return {\n            "robot_position": {"x": 0.0, "y": 0.0, "theta": 0.0},\n            "robot_battery": 0.85,\n            "detected_objects": [],\n            "navigation_map": "available",\n            "manipulation_capabilities": ["pick_up", "place", "move_arm"],\n            "current_task": "idle"\n        }\n\n    async def _validate_plan(self, plan: List[Dict[str, Any]], environment_state: Dict[str, Any]) -> bool:\n        """\n        Validate if the plan is feasible in the current environment\n        """\n        evaluation = await self.llm_planner.evaluate_plan_feasibility(plan, environment_state)\n        return evaluation.get("feasible", False)\n\n    async def _refine_plan_with_feedback(self, plan: List[Dict[str, Any]],\n                                       environment_state: Dict[str, Any]) -> Optional[List[Dict[str, Any]]]:\n        """\n        Refine a plan based on feasibility feedback\n        """\n        evaluation = await self.llm_planner.evaluate_plan_feasibility(plan, environment_state)\n\n        if evaluation.get("issues"):\n            feedback = f"The plan has the following issues: {\', \'.join(evaluation[\'issues\'])}. Please address these issues."\n            refined_plan = await self.llm_planner.refine_plan(plan, feedback)\n            return refined_plan\n\n        return plan\n\n    def get_plan_complexity(self, plan: List[Dict[str, Any]]) -> Dict[str, Any]:\n        """\n        Analyze the complexity of a plan\n        """\n        complexity_metrics = {\n            "total_steps": len(plan),\n            "action_types": set(),\n            "estimated_duration": 0.0,\n            "risk_level": "low",  # low, medium, high\n            "dependency_depth": 0\n        }\n\n        for step in plan:\n            action_type = step.get("action", "unknown")\n            complexity_metrics["action_types"].add(action_type)\n\n            # Estimate duration based on action type\n            if action_type in ["navigate_to", "move"]:\n                complexity_metrics["estimated_duration"] += 10.0\n            elif action_type in ["pick_up", "place"]:\n                complexity_metrics["estimated_duration"] += 5.0\n            elif action_type in ["detect_object"]:\n                complexity_metrics["estimated_duration"] += 3.0\n            else:\n                complexity_metrics["estimated_duration"] += 2.0\n\n        complexity_metrics["action_types"] = list(complexity_metrics["action_types"])\n\n        # Determine risk level based on complexity\n        if len(plan) > 10:\n            complexity_metrics["risk_level"] = "high"\n        elif len(plan) > 5:\n            complexity_metrics["risk_level"] = "medium"\n\n        return complexity_metrics\n\n    async def optimize_plan(self, plan: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        """\n        Optimize a plan for efficiency\n        """\n        # This would involve various optimization techniques\n        # such as parallelizing independent actions, reducing redundant steps, etc.\n\n        optimized_plan = []\n\n        # Group independent actions that can be executed in parallel\n        parallelizable_actions = []\n        sequential_actions = []\n\n        for step in plan:\n            if step.get("dependencies", []):\n                sequential_actions.append(step)\n            else:\n                parallelizable_actions.append(step)\n\n        # For now, just return the original plan\n        # In a real implementation, this would contain optimization logic\n        return plan\n'})}),"\n",(0,i.jsx)(n.h3,{id:"step-5-create-the-action-executor",children:"Step 5: Create the Action Executor"}),"\n",(0,i.jsx)(n.p,{children:"Now let's create the action executor that will map the planned actions to ROS 2 services and actions:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# cognitive_planning/cognitive_planning/execution/executor.py\nimport rclpy\nfrom rclpy.action import ActionClient\nfrom rclpy.client import Client\nfrom rclpy.qos import QoSProfile\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import String\nfrom typing import Dict, Any, Optional\nimport asyncio\nimport time\n\nclass ActionExecutor:\n    def __init__(self, node):\n        self.node = node\n        self.logger = node.get_logger()\n\n        # Initialize action and service clients\n        self._init_clients()\n\n    def _init_clients(self):\n        """Initialize all necessary ROS 2 clients"""\n        # Navigation action client\n        self.nav_client = ActionClient(\n            self.node,\n            \'nav2_msgs/action/NavigateToPose\',\n            \'navigate_to_pose\'\n        )\n\n        # Manipulation service clients\n        self.pick_service = self.node.create_client(\n            \'manipulation_msgs/srv/PickUp\',\n            \'pick_up_object\'\n        )\n\n        self.place_service = self.node.create_client(\n            \'manipulation_msgs/srv/Place\',\n            \'place_object\'\n        )\n\n        # Speech service client\n        self.speech_service = self.node.create_client(\n            \'tts_msgs/srv/Speak\',\n            \'speak_text\'\n        )\n\n        # Perception service client\n        self.detection_service = self.node.create_client(\n            \'vision_msgs/srv/DetectObjects\',\n            \'detect_objects\'\n        )\n\n    async def execute_action(self, action: Dict[str, Any]) -> bool:\n        """\n        Execute a single action from the plan\n        """\n        action_type = action.get("action", "")\n        parameters = action.get("parameters", {})\n        timeout = action.get("timeout", 30.0)\n\n        self.logger.info(f"Executing action: {action_type} with params: {parameters}")\n\n        try:\n            if action_type == "navigate_to":\n                return await self._execute_navigation_action(parameters, timeout)\n            elif action_type == "detect_object":\n                return await self._execute_detection_action(parameters, timeout)\n            elif action_type == "pick_up":\n                return await self._execute_pickup_action(parameters, timeout)\n            elif action_type == "place":\n                return await self._execute_place_action(parameters, timeout)\n            elif action_type == "speak":\n                return await self._execute_speak_action(parameters, timeout)\n            elif action_type == "wait":\n                return await self._execute_wait_action(parameters, timeout)\n            elif action_type == "call_service":\n                return await self._execute_service_call(parameters, timeout)\n            else:\n                self.logger.error(f"Unknown action type: {action_type}")\n                return False\n\n        except Exception as e:\n            self.logger.error(f"Error executing action {action_type}: {str(e)}")\n            return False\n\n    async def _execute_navigation_action(self, params: Dict[str, Any], timeout: float) -> bool:\n        """Execute navigation action"""\n        target_pose = PoseStamped()\n        target_pose.header.frame_id = params.get("frame_id", "map")\n        target_pose.header.stamp = self.node.get_clock().now().to_msg()\n\n        target_pose.pose.position.x = params.get("x", 0.0)\n        target_pose.pose.position.y = params.get("y", 0.0)\n        target_pose.pose.position.z = params.get("z", 0.0)\n\n        # Set orientation (assuming quaternion parameters)\n        target_pose.pose.orientation.w = params.get("orientation_w", 1.0)\n        target_pose.pose.orientation.x = params.get("orientation_x", 0.0)\n        target_pose.pose.orientation.y = params.get("orientation_y", 0.0)\n        target_pose.pose.orientation.z = params.get("orientation_z", 0.0)\n\n        # Wait for action server\n        if not self.nav_client.wait_for_server(timeout_sec=5.0):\n            self.logger.error("Navigation action server not available")\n            return False\n\n        # Send goal\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose = target_pose\n\n        future = self.nav_client.send_goal_async(goal_msg)\n\n        # Wait for result with timeout\n        try:\n            goal_handle = await asyncio.wait_for(future, timeout=timeout)\n            if not goal_handle.accepted:\n                self.logger.error("Navigation goal was rejected")\n                return False\n\n            result_future = goal_handle.get_result_async()\n            result = await asyncio.wait_for(result_future, timeout=timeout)\n\n            return result.result.status == GoalStatus.STATUS_SUCCEEDED\n\n        except asyncio.TimeoutError:\n            self.logger.error("Navigation action timed out")\n            return False\n\n    async def _execute_detection_action(self, params: Dict[str, Any], timeout: float) -> bool:\n        """Execute object detection action"""\n        if not self.detection_service.wait_for_service(timeout_sec=5.0):\n            self.logger.error("Detection service not available")\n            return False\n\n        request = DetectObjects.Request()\n        request.target_object = params.get("target", "")\n        request.search_area = params.get("area", "current_view")\n\n        future = self.detection_service.call_async(request)\n\n        try:\n            result = await asyncio.wait_for(future, timeout=timeout)\n            return result.success\n        except asyncio.TimeoutError:\n            self.logger.error("Detection action timed out")\n            return False\n\n    async def _execute_pickup_action(self, params: Dict[str, Any], timeout: float) -> bool:\n        """Execute pickup action"""\n        if not self.pick_service.wait_for_service(timeout_sec=5.0):\n            self.logger.error("Pickup service not available")\n            return False\n\n        request = PickUp.Request()\n        request.object_name = params.get("object", "")\n        request.grasp_pose = self._dict_to_pose(params.get("grasp_pose", {}))\n\n        future = self.pick_service.call_async(request)\n\n        try:\n            result = await asyncio.wait_for(future, timeout=timeout)\n            return result.success\n        except asyncio.TimeoutError:\n            self.logger.error("Pickup action timed out")\n            return False\n\n    async def _execute_place_action(self, params: Dict[str, Any], timeout: float) -> bool:\n        """Execute place action"""\n        if not self.place_service.wait_for_service(timeout_sec=5.0):\n            self.logger.error("Place service not available")\n            return False\n\n        request = Place.Request()\n        request.object_name = params.get("object", "")\n        request.place_pose = self._dict_to_pose(params.get("place_pose", {}))\n\n        future = self.place_service.call_async(request)\n\n        try:\n            result = await asyncio.wait_for(future, timeout=timeout)\n            return result.success\n        except asyncio.TimeoutError:\n            self.logger.error("Place action timed out")\n            return False\n\n    async def _execute_speak_action(self, params: Dict[str, Any], timeout: float) -> bool:\n        """Execute speech action"""\n        if not self.speech_service.wait_for_service(timeout_sec=5.0):\n            self.logger.error("Speech service not available")\n            return False\n\n        request = Speak.Request()\n        request.text = params.get("text", "")\n\n        future = self.speech_service.call_async(request)\n\n        try:\n            result = await asyncio.wait_for(future, timeout=timeout)\n            return result.success\n        except asyncio.TimeoutError:\n            self.logger.error("Speech action timed out")\n            return False\n\n    async def _execute_wait_action(self, params: Dict[str, Any], timeout: float) -> bool:\n        """Execute wait action"""\n        wait_duration = params.get("duration", 1.0)\n\n        # Use a timer to wait\n        start_time = time.time()\n        while time.time() - start_time < wait_duration:\n            await asyncio.sleep(0.1)  # Non-blocking sleep\n\n        return True\n\n    async def _execute_service_call(self, params: Dict[str, Any], timeout: float) -> bool:\n        """Execute a generic service call"""\n        service_name = params.get("service_name", "")\n        service_type = params.get("service_type", "")\n        service_params = params.get("parameters", {})\n\n        # This would dynamically create and call the appropriate service\n        # For now, we\'ll log the call\n        self.logger.info(f"Calling service {service_name} with params: {service_params}")\n\n        # In a real implementation, this would dynamically create the service client\n        # and call it with the provided parameters\n        return True\n\n    def _dict_to_pose(self, pose_dict: Dict[str, Any]):\n        """Convert dictionary to Pose message"""\n        from geometry_msgs.msg import Pose\n        pose = Pose()\n\n        pose.position.x = pose_dict.get("x", 0.0)\n        pose.position.y = pose_dict.get("y", 0.0)\n        pose.position.z = pose_dict.get("z", 0.0)\n\n        pose.orientation.w = pose_dict.get("w", 1.0)\n        pose.orientation.x = pose_dict.get("x", 0.0)\n        pose.orientation.y = pose_dict.get("y", 0.0)\n        pose.orientation.z = pose_dict.get("z", 0.0)\n\n        return pose\n\n    def cancel_current_action(self):\n        """Cancel the currently executing action"""\n        # This would cancel the current action if possible\n        self.logger.info("Canceling current action")\n        # Implementation would depend on the specific action type\n'})})]})}function _(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},8453(e,n,t){t.d(n,{R:()=>o,x:()=>r});var a=t(6540);const i={},s=a.createContext(i);function o(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);
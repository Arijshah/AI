"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[271],{6792(e,n,t){t.r(n),t.d(n,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"physical-ai/introduction-to-physical-ai/humanoid-robotics-overview","title":"Humanoid Robotics Overview","description":"Overview","source":"@site/docs/physical-ai/introduction-to-physical-ai/humanoid-robotics-overview.md","sourceDirName":"physical-ai/introduction-to-physical-ai","slug":"/physical-ai/introduction-to-physical-ai/humanoid-robotics-overview","permalink":"/physical-ai-book/docs/physical-ai/introduction-to-physical-ai/humanoid-robotics-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/arijh/physical-ai-book/tree/main/packages/create-docusaurus/templates/shared/docs/physical-ai/introduction-to-physical-ai/humanoid-robotics-overview.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Humanoid Robotics Overview","title":"Humanoid Robotics Overview"},"sidebar":"docs","previous":{"title":"What is Physical AI?","permalink":"/physical-ai-book/docs/physical-ai/introduction-to-physical-ai/what-is-physical-ai"},"next":{"title":"Tools and Platforms","permalink":"/physical-ai-book/docs/physical-ai/introduction-to-physical-ai/tools-and-platforms"}}');var a=t(4848),o=t(8453);const s={sidebar_label:"Humanoid Robotics Overview",title:"Humanoid Robotics Overview"},l="Humanoid Robotics Overview",r={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Hands-on Steps",id:"hands-on-steps",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Small Simulation",id:"small-simulation",level:2},{value:"Quick Recap",id:"quick-recap",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"humanoid-robotics-overview",children:"Humanoid Robotics Overview"})}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(n.p,{children:"Humanoid robots represent one of the most compelling applications of Physical AI, designed to mimic human form and behavior. These robots are engineered to interact naturally with human environments, leveraging anthropomorphic features like bipedal locomotion, articulated limbs, and facial expressions."}),"\n",(0,a.jsx)(n.p,{children:"This lesson explores the fundamental principles behind humanoid robotics, examining their design considerations, control systems, and the challenges that make them particularly complex Physical AI systems."}),"\n",(0,a.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,a.jsx)(n.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Understand the design principles of humanoid robots"}),"\n",(0,a.jsx)(n.li,{children:"Identify key components of humanoid robot systems"}),"\n",(0,a.jsx)(n.li,{children:"Recognize the challenges in humanoid robot control and balance"}),"\n",(0,a.jsx)(n.li,{children:"Appreciate the applications of humanoid robots in various domains"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"hands-on-steps",children:"Hands-on Steps"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Analyze Humanoid Robot Anatomy"}),": Study the mechanical design of humanoid robots"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Explore Balance Control Systems"}),": Understand how robots maintain stability"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Implement Simple Balance Algorithm"}),": Create a basic balance simulation"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Examine Motion Planning"}),": Learn how humanoid robots plan movements"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Understanding of basic physics (center of mass, stability)"}),"\n",(0,a.jsx)(n.li,{children:"Basic Python programming knowledge"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,a.jsx)(n.p,{children:"Let's explore the concept of balance in humanoid robots by simulating a simplified inverted pendulum model, which is often used to represent bipedal balance:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import numpy as np\nimport matplotlib.pyplot as plt\n\nclass InvertedPendulum:\n    """\n    Simplified model of a humanoid robot\'s balance system\n    represented as an inverted pendulum\n    """\n    def __init__(self, length=1.0, mass=1.0, gravity=9.81):\n        self.length = length  # Height of the center of mass\n        self.mass = mass      # Mass of the robot\n        self.gravity = gravity\n        self.angle = 0.1      # Initial angle (small disturbance)\n        self.angular_velocity = 0.0\n\n    def update(self, torque=0, dt=0.01):\n        """\n        Update the pendulum state based on applied torque\n        Using the equation: I * \u03b8\'\' = mgl*sin(\u03b8) + \u03c4\n        where I is moment of inertia, \u03c4 is torque\n        """\n        # Moment of inertia for point mass at length l\n        inertia = self.mass * self.length ** 2\n\n        # Calculate angular acceleration\n        angular_acceleration = (self.mass * self.gravity * self.length * np.sin(self.angle) + torque) / inertia\n\n        # Update state using Euler integration\n        self.angular_velocity += angular_acceleration * dt\n        self.angle += self.angular_velocity * dt\n\n        return self.angle, self.angular_velocity\n\nclass BalanceController:\n    """\n    Simple PID controller for maintaining balance\n    """\n    def __init__(self, kp=100.0, ki=1.0, kd=20.0):\n        self.kp = kp  # Proportional gain\n        self.ki = ki  # Integral gain\n        self.kd = kd  # Derivative gain\n        self.error_sum = 0\n        self.last_error = 0\n\n    def compute_torque(self, angle, target_angle=0, dt=0.01):\n        """Compute corrective torque based on angle error"""\n        error = target_angle - angle\n\n        # Update integral and derivative terms\n        self.error_sum += error * dt\n        error_derivative = (error - self.last_error) / dt if dt > 0 else 0\n\n        # Calculate control output\n        torque = (self.kp * error +\n                 self.ki * self.error_sum +\n                 self.kd * error_derivative)\n\n        self.last_error = error\n        return torque\n\ndef simulate_balance_control(duration=10, dt=0.01):\n    """\n    Simulate a humanoid robot balancing using PID control\n    """\n    pendulum = InvertedPendulum(length=0.8, mass=50)  # Approximate human COM\n    controller = BalanceController(kp=150, ki=5, kd=30)\n\n    time_points = []\n    angle_points = []\n    torque_points = []\n\n    for t in np.arange(0, duration, dt):\n        # Apply control torque to maintain balance\n        torque = controller.compute_torque(pendulum.angle, dt=dt)\n\n        # Update pendulum state\n        angle, ang_vel = pendulum.update(torque, dt)\n\n        # Log data\n        time_points.append(t)\n        angle_points.append(angle)\n        torque_points.append(torque)\n\n        # Occasionally add disturbances to simulate real-world\n        if int(t/dt) % 100 == 0 and t > 1:\n            pendulum.angle += np.random.uniform(-0.05, 0.05)\n\n    return time_points, angle_points, torque_points\n\n# Run the simulation\ntime_data, angle_data, torque_data = simulate_balance_control()\n\nprint(f"Balance simulation completed for {len(time_data)} time steps")\nprint(f"Final angle: {angle_data[-1]:.4f} radians")\nprint(f"Average absolute angle: {np.mean(np.abs(angle_data)):.4f} radians")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"small-simulation",children:"Small Simulation"}),"\n",(0,a.jsx)(n.p,{children:"Now let's create a more sophisticated simulation that models walking using the Zero Moment Point (ZMP) concept, which is crucial for humanoid robot locomotion:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'class WalkingPatternGenerator:\n    """\n    Generate walking patterns using ZMP-based approach\n    """\n    def __init__(self, step_length=0.3, step_height=0.1, step_duration=0.8, com_height=0.8):\n        self.step_length = step_length\n        self.step_height = step_height\n        self.step_duration = step_duration\n        self.com_height = com_height  # Center of mass height\n\n    def zmp_trajectory(self, steps=5):\n        """Generate ZMP trajectory for walking"""\n        # Time parameters\n        dt = 0.01\n        total_time = steps * self.step_duration\n        time_points = np.arange(0, total_time, dt)\n\n        zmp_x = []\n        zmp_y = []\n\n        for t in time_points:\n            # Determine which step we\'re in\n            step_num = int(t / self.step_duration)\n\n            if step_num >= steps:\n                break\n\n            # Phase within current step cycle\n            phase = (t % self.step_duration) / self.step_duration\n\n            # X position follows the step pattern\n            x_pos = step_num * self.step_length\n            # Add smooth transition between steps\n            if phase < 0.5:  # Acceleration phase\n                x_pos += (phase * 2) * (self.step_length / 2)\n            else:  # Deceleration phase\n                x_pos += (1 - (1 - phase) * 2) * (self.step_length / 2)\n\n            # Y position alternates between feet (stabilizing)\n            if step_num % 2 == 0:  # Right foot stance\n                y_pos = -0.1 if phase < 0.5 else 0.1\n            else:  # Left foot stance\n                y_pos = 0.1 if phase < 0.5 else -0.1\n\n            zmp_x.append(x_pos)\n            zmp_y.append(y_pos)\n\n        return np.array(zmp_x), np.array(zmp_y), time_points[:len(zmp_x)]\n\n    def com_trajectory_from_zmp(self, zmp_x, zmp_y):\n        """\n        Calculate CoM trajectory from ZMP using inverted pendulum model\n        """\n        omega = np.sqrt(9.81 / self.com_height)  # Natural frequency\n\n        # Simplified relationship: CoM = ZMP + (CoM_height / gravity) * ZMP_double_dot\n        # For simplicity, we\'ll use a filtered version of ZMP for CoM\n        com_x = np.zeros_like(zmp_x)\n        com_y = np.zeros_like(zmp_y)\n\n        # Smooth the ZMP to get CoM trajectory\n        for i in range(len(zmp_x)):\n            if i == 0:\n                com_x[i] = zmp_x[i] * 0.8  # CoM slightly follows ZMP\n                com_y[i] = zmp_y[i] * 0.8\n            else:\n                # Low-pass filter effect\n                alpha = 0.05\n                com_x[i] = alpha * zmp_x[i] + (1 - alpha) * com_x[i-1]\n                com_y[i] = alpha * zmp_y[i] + (1 - alpha) * com_y[i-1]\n\n        return com_x, com_y\n\ndef simulate_humanoid_walking():\n    """Simulate humanoid walking pattern"""\n    walker = WalkingPatternGenerator()\n\n    # Generate trajectories\n    zmp_x, zmp_y, time_points = walker.zmp_trajectory(steps=4)\n    com_x, com_y = walker.com_trajectory_from_zmp(zmp_x, zmp_y)\n\n    # Plot the results\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n\n    # Plot ZMP and CoM trajectories\n    ax1.plot(time_points, zmp_x, label=\'ZMP X\', linewidth=2)\n    ax1.plot(time_points, com_x, label=\'CoM X\', linestyle=\'--\', linewidth=2)\n    ax1.set_ylabel(\'X Position (m)\')\n    ax1.set_title(\'Humanoid Walking: X Direction\')\n    ax1.legend()\n    ax1.grid(True)\n\n    ax2.plot(time_points, zmp_y, label=\'ZMP Y\', linewidth=2)\n    ax2.plot(time_points, com_y, label=\'CoM Y\', linestyle=\'--\', linewidth=2)\n    ax2.set_xlabel(\'Time (s)\')\n    ax2.set_ylabel(\'Y Position (m)\')\n    ax2.set_title(\'Humanoid Walking: Y Direction\')\n    ax2.legend()\n    ax2.grid(True)\n\n    plt.tight_layout()\n    plt.show()\n\n    return time_points, zmp_x, zmp_y, com_x, com_y\n\n# Run walking simulation\ntime_walk, zmp_x, zmp_y, com_x, com_y = simulate_humanoid_walking()\nprint(f"Walking simulation completed for {len(time_walk)} time steps")\nprint(f"Traveled distance: {zmp_x[-1]:.2f} meters")\n'})}),"\n",(0,a.jsx)(n.h2,{id:"quick-recap",children:"Quick Recap"}),"\n",(0,a.jsx)(n.p,{children:"In this lesson, we've explored:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Design Principles"}),": Humanoid robots mimic human form to interact naturally with human environments"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Balance Challenges"}),": Maintaining stability using control systems like PID controllers"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Locomotion"}),": Walking patterns using concepts like Zero Moment Point (ZMP)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Complexity"}),": Why humanoid robots are among the most challenging Physical AI systems"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Humanoid robotics pushes the boundaries of Physical AI by requiring sophisticated integration of perception, planning, control, and adaptation. The challenges of balance, coordination, and safe interaction with humans make humanoid robots a fascinating testbed for advanced Physical AI techniques."}),"\n",(0,a.jsx)(n.p,{children:"The next lesson will focus on the tools and platforms that enable the development of Physical AI systems and humanoid robots."})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}},8453(e,n,t){t.d(n,{R:()=>s,x:()=>l});var i=t(6540);const a={},o=i.createContext(a);function s(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);
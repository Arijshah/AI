"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[436],{1486(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"physical-ai/the-digital-twin-gazebo-unity/introduction-to-gazebo-simulation","title":"Introduction to Gazebo Simulation","description":"Overview","source":"@site/docs/physical-ai/the-digital-twin-gazebo-unity/introduction-to-gazebo-simulation.md","sourceDirName":"physical-ai/the-digital-twin-gazebo-unity","slug":"/physical-ai/the-digital-twin-gazebo-unity/introduction-to-gazebo-simulation","permalink":"/physical-ai-book/docs/physical-ai/the-digital-twin-gazebo-unity/introduction-to-gazebo-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/arijh/physical-ai-book/tree/main/packages/create-docusaurus/templates/shared/docs/physical-ai/the-digital-twin-gazebo-unity/introduction-to-gazebo-simulation.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Introduction to Gazebo Simulation","title":"Introduction to Gazebo Simulation"},"sidebar":"docs","previous":{"title":"Practical ROS 2 Workflows","permalink":"/physical-ai-book/docs/physical-ai/the-robotic-nervous-system-ros2/practical-ros2-workflows"},"next":{"title":"Physics and Collision Modeling","permalink":"/physical-ai-book/docs/physical-ai/the-digital-twin-gazebo-unity/physics-and-collision-modeling"}}');var s=i(4848),t=i(8453);const a={sidebar_label:"Introduction to Gazebo Simulation",title:"Introduction to Gazebo Simulation"},r="Introduction to Gazebo Simulation",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Hands-on Steps",id:"hands-on-steps",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Small Simulation",id:"small-simulation",level:2},{value:"Quick Recap",id:"quick-recap",level:2}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"introduction-to-gazebo-simulation",children:"Introduction to Gazebo Simulation"})}),"\n",(0,s.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(e.p,{children:'Gazebo is a powerful physics-based simulation environment that serves as a "digital twin" for robotic systems. It provides realistic physics simulation, sensor modeling, and visual rendering that allows developers to test and validate robot behaviors in a safe, controlled environment before deploying to real hardware. This lesson introduces the core concepts of Gazebo simulation and demonstrates how to create and interact with simulated robots.'}),"\n",(0,s.jsx)(e.p,{children:"Gazebo is particularly valuable for Physical AI development because it enables rapid prototyping, testing of complex scenarios, and safe experimentation with robot behaviors that would be risky or expensive to test on real hardware."}),"\n",(0,s.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,s.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Understand the architecture and components of Gazebo simulation"}),"\n",(0,s.jsx)(e.li,{children:"Set up a basic Gazebo environment with ROS 2 integration"}),"\n",(0,s.jsx)(e.li,{children:"Create simple simulation worlds with objects and obstacles"}),"\n",(0,s.jsx)(e.li,{children:"Spawn and control robots in simulation"}),"\n",(0,s.jsx)(e.li,{children:"Use Gazebo's physics engine and sensor models"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"hands-on-steps",children:"Hands-on Steps"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Gazebo Installation"}),": Set up Gazebo with ROS 2 integration"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Basic World Creation"}),": Create a simple simulation environment"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Robot Spawning"}),": Add a robot model to the simulation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sensor Integration"}),": Add and configure basic sensors"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Control Interface"}),": Connect to ROS 2 for robot control"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Understanding of ROS 2 concepts and basic node development"}),"\n",(0,s.jsx)(e.li,{children:"Knowledge of URDF for robot modeling (from Chapter 2)"}),"\n",(0,s.jsx)(e.li,{children:"Basic understanding of physics concepts (mass, friction, collision)"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,s.jsx)(e.p,{children:"Let's start by creating a basic Gazebo world file:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'\x3c!-- basic_world.world --\x3e\n<?xml version="1.0" ?>\n<sdf version="1.7">\n  <world name="basic_world">\n    \x3c!-- Include the default camera sensor --\x3e\n    <include>\n      <uri>model://sun</uri>\n    </include>\n\n    \x3c!-- Add ground plane --\x3e\n    <include>\n      <uri>model://ground_plane</uri>\n    </include>\n\n    \x3c!-- Add a simple box obstacle --\x3e\n    <model name="box_obstacle">\n      <pose>2 0 0.5 0 0 0</pose>\n      <link name="box_link">\n        <collision name="box_collision">\n          <geometry>\n            <box>\n              <size>1 1 1</size>\n            </box>\n          </geometry>\n        </collision>\n        <visual name="box_visual">\n          <geometry>\n            <box>\n              <size>1 1 1</size>\n          </geometry>\n          <material>\n            <ambient>0.8 0.2 0.2 1</ambient>\n            <diffuse>0.8 0.2 0.2 1</diffuse>\n            <specular>0.8 0.2 0.2 1</specular>\n          </material>\n        </visual>\n        <inertial>\n          <mass>1.0</mass>\n          <inertia>\n            <ixx>0.1667</ixx>\n            <ixy>0.0</ixy>\n            <ixz>0.0</ixz>\n            <iyy>0.1667</iyy>\n            <iyz>0.0</iyz>\n            <izz>0.1667</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n\n    \x3c!-- Add a simple cylinder obstacle --\x3e\n    <model name="cylinder_obstacle">\n      <pose>-2 1 0.5 0 0 0</pose>\n      <link name="cylinder_link">\n        <collision name="cylinder_collision">\n          <geometry>\n            <cylinder>\n              <radius>0.3</radius>\n              <length>1.0</length>\n            </cylinder>\n          </geometry>\n        </collision>\n        <visual name="cylinder_visual">\n          <geometry>\n            <cylinder>\n              <radius>0.3</radius>\n              <length>1.0</length>\n            </cylinder>\n          </geometry>\n          <material>\n            <ambient>0.2 0.8 0.2 1</ambient>\n            <diffuse>0.2 0.8 0.2 1</diffuse>\n            <specular>0.2 0.8 0.2 1</specular>\n          </material>\n        </visual>\n        <inertial>\n          <mass>1.0</mass>\n          <inertia>\n            <ixx>0.125</ixx>\n            <ixy>0.0</ixy>\n            <ixz>0.0</ixz>\n            <iyy>0.125</iyy>\n            <iyz>0.0</iyz>\n            <izz>0.09</izz>\n          </inertia>\n        </inertial>\n      </link>\n    </model>\n  </world>\n</sdf>\n'})}),"\n",(0,s.jsx)(e.p,{children:"Now let's create a simple robot model that can be used in Gazebo:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-xml",children:'\x3c!-- simple_robot.urdf --\x3e\n<?xml version="1.0"?>\n<robot name="simple_robot">\n  \x3c!-- Materials --\x3e\n  <material name="blue">\n    <color rgba="0.0 0.0 0.8 1.0"/>\n  </material>\n  <material name="green">\n    <color rgba="0.0 0.8 0.0 1.0"/>\n  </material>\n  <material name="red">\n    <color rgba="0.8 0.0 0.0 1.0"/>\n  </material>\n  <material name="white">\n    <color rgba="1.0 1.0 1.0 1.0"/>\n  </material>\n\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <cylinder length="0.2" radius="0.2"/>\n      </geometry>\n      <material name="white"/>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder length="0.2" radius="0.2"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="5.0"/>\n      <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.1" iyz="0.0" izz="0.1"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Left Wheel --\x3e\n  <link name="left_wheel">\n    <visual>\n      <geometry>\n        <cylinder length="0.05" radius="0.1"/>\n      </geometry>\n      <material name="blue"/>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder length="0.05" radius="0.1"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.5"/>\n      <inertia ixx="0.001" ixy="0.0" ixz="0.0" iyy="0.001" iyz="0.0" izz="0.001"/>\n    </inertial>\n  </link>\n\n  <joint name="left_wheel_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="left_wheel"/>\n    <origin xyz="0 0.15 -0.05" rpy="1.57 0 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  \x3c!-- Right Wheel --\x3e\n  <link name="right_wheel">\n    <visual>\n      <geometry>\n        <cylinder length="0.05" radius="0.1"/>\n      </geometry>\n      <material name="blue"/>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder length="0.05" radius="0.1"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.5"/>\n      <inertia ixx="0.001" ixy="0.0" ixz="0.0" iyy="0.001" iyz="0.0" izz="0.001"/>\n    </inertial>\n  </link>\n\n  <joint name="right_wheel_joint" type="continuous">\n    <parent link="base_link"/>\n    <child link="right_wheel"/>\n    <origin xyz="0 -0.15 -0.05" rpy="1.57 0 0"/>\n    <axis xyz="0 0 1"/>\n  </joint>\n\n  \x3c!-- Camera Mount --\x3e\n  <link name="camera_mount">\n    <visual>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n      <material name="red"/>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.05 0.05 0.05"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="0.1"/>\n      <inertia ixx="0.0001" ixy="0.0" ixz="0.0" iyy="0.0001" iyz="0.0" izz="0.0001"/>\n    </inertial>\n  </link>\n\n  <joint name="camera_joint" type="fixed">\n    <parent link="base_link"/>\n    <child link="camera_mount"/>\n    <origin xyz="0.15 0 0.05" rpy="0 0 0"/>\n  </joint>\n\n  \x3c!-- Gazebo-specific plugins and sensors --\x3e\n  <gazebo reference="base_link">\n    <material>Gazebo/White</material>\n  </gazebo>\n\n  <gazebo reference="left_wheel">\n    <material>Gazebo/Blue</material>\n    <mu1>1.0</mu1>\n    <mu2>1.0</mu2>\n    <kp>1000000.0</kp>\n    <kd>100.0</kd>\n  </gazebo>\n\n  <gazebo reference="right_wheel">\n    <material>Gazebo/Blue</material>\n    <mu1>1.0</mu1>\n    <mu2>1.0</mu2>\n    <kp>1000000.0</kp>\n    <kd>100.0</kd>\n  </gazebo>\n\n  \x3c!-- Differential drive plugin --\x3e\n  <gazebo>\n    <plugin name="differential_drive" filename="libgazebo_ros_diff_drive.so">\n      <ros>\n        <namespace>/simple_robot</namespace>\n        <remapping>cmd_vel:=cmd_vel</remapping>\n        <remapping>odom:=odom</remapping>\n      </ros>\n      <left_joint>left_wheel_joint</left_joint>\n      <right_joint>right_wheel_joint</right_joint>\n      <wheel_separation>0.3</wheel_separation>\n      <wheel_diameter>0.2</wheel_diameter>\n      <max_wheel_torque>20</max_wheel_torque>\n      <max_wheel_acceleration>1.0</max_wheel_acceleration>\n      <publish_odom>true</publish_odom>\n      <publish_odom_tf>true</publish_odom_tf>\n      <publish_wheel_tf>true</publish_wheel_tf>\n      <odometry_frame>odom</odometry_frame>\n      <robot_base_frame>base_link</robot_base_frame>\n    </plugin>\n  </gazebo>\n\n  \x3c!-- Camera sensor plugin --\x3e\n  <gazebo reference="camera_mount">\n    <sensor name="camera" type="camera">\n      <pose>0 0 0 0 0 0</pose>\n      <visualize>true</visualize>\n      <update_rate>30</update_rate>\n      <camera name="head">\n        <horizontal_fov>1.3962634</horizontal_fov>\n        <image>\n          <width>640</width>\n          <height>480</height>\n          <format>R8G8B8</format>\n        </image>\n        <clip>\n          <near>0.1</near>\n          <far>100</far>\n        </clip>\n      </camera>\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n        <ros>\n          <namespace>/simple_robot</namespace>\n          <remapping>image_raw:=camera/image_raw</remapping>\n          <remapping>camera_info:=camera/camera_info</remapping>\n        </ros>\n        <camera_name>camera</camera_name>\n        <image_topic_name>image_raw</image_topic_name>\n        <camera_info_topic_name>camera_info</camera_info_topic_name>\n        <frame_name>camera_mount</frame_name>\n      </plugin>\n    </sensor>\n  </gazebo>\n</robot>\n'})}),"\n",(0,s.jsx)(e.p,{children:"Now let's create a ROS 2 node that can interact with our simulated robot:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'# gazebo_robot_controller.py\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, Pose\nfrom nav_msgs.msg import Odometry\nfrom sensor_msgs.msg import LaserScan, Image\nfrom std_msgs.msg import String\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\nclass GazeboRobotController(Node):\n    """\n    Controller for interacting with a robot in Gazebo simulation\n    """\n    def __init__(self):\n        super().__init__(\'gazebo_robot_controller\')\n\n        # Publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/simple_robot/cmd_vel\', 10)\n        self.status_pub = self.create_publisher(String, \'/robot_status\', 10)\n\n        # Subscribers\n        self.odom_sub = self.create_subscription(\n            Odometry, \'/simple_robot/odom\', self.odom_callback, 10)\n\n        self.scan_sub = self.create_subscription(\n            LaserScan, \'/simple_robot/scan\', self.scan_callback, 10)\n\n        self.image_sub = self.create_subscription(\n            Image, \'/simple_robot/camera/image_raw\', self.image_callback, 10)\n\n        # Timer for control loop\n        self.control_timer = self.create_timer(0.1, self.control_loop)\n\n        # Robot state\n        self.current_pose = Pose()\n        self.current_twist = Twist()\n        self.laser_ranges = []\n        self.obstacle_detected = False\n        self.obstacle_distance = float(\'inf\')\n        self.robot_state = "IDLE"\n\n        # Image processing\n        self.cv_bridge = CvBridge()\n        self.latest_image = None\n\n        # Control parameters\n        self.linear_speed = 0.3\n        self.angular_speed = 0.5\n        self.obstacle_threshold = 1.0\n\n        self.get_logger().info("Gazebo Robot Controller initialized")\n\n    def odom_callback(self, msg):\n        """Process odometry data"""\n        self.current_pose = msg.pose.pose\n        self.current_twist = msg.twist.twist\n\n    def scan_callback(self, msg):\n        """Process laser scan data"""\n        self.laser_ranges = msg.ranges\n\n        # Check for obstacles in front (\xb130 degrees)\n        front_ranges = msg.ranges[330:] + msg.ranges[:30]\n        front_ranges = [r for r in front_ranges if not np.isnan(r) and 0.1 < r < 10.0]\n\n        if front_ranges:\n            self.obstacle_distance = min(front_ranges)\n            self.obstacle_detected = self.obstacle_distance < self.obstacle_threshold\n        else:\n            self.obstacle_distance = float(\'inf\')\n            self.obstacle_detected = False\n\n    def image_callback(self, msg):\n        """Process camera image data"""\n        try:\n            # Convert ROS Image message to OpenCV image\n            self.latest_image = self.cv_bridge.imgmsg_to_cv2(msg, "bgr8")\n        except Exception as e:\n            self.get_logger().error(f"Could not convert image: {e}")\n\n    def control_loop(self):\n        """Main control loop for the robot"""\n        cmd = Twist()\n\n        if self.obstacle_detected:\n            # Stop and rotate to avoid obstacle\n            self.robot_state = "AVOIDING_OBSTACLE"\n            cmd.linear.x = 0.0\n            cmd.angular.z = self.angular_speed\n        else:\n            # Move forward\n            self.robot_state = "MOVING_FORWARD"\n            cmd.linear.x = self.linear_speed\n            cmd.angular.z = 0.0\n\n        # Publish command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = f"State: {self.robot_state}, Pos: ({self.current_pose.position.x:.2f}, {self.current_pose.position.y:.2f}), " \\\n                         f"Obstacle: {self.obstacle_detected}, Distance: {self.obstacle_distance:.2f}m"\n        self.status_pub.publish(status_msg)\n\n        # Process image if available (simple color detection example)\n        if self.latest_image is not None:\n            # Simple color detection - find red objects\n            hsv = cv2.cvtColor(self.latest_image, cv2.COLOR_BGR2HSV)\n            lower_red = np.array([0, 100, 100])\n            upper_red = np.array([10, 255, 255])\n            mask = cv2.inRange(hsv, lower_red, upper_red)\n\n            # Find contours\n            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n            if contours:\n                # Find the largest contour\n                largest_contour = max(contours, key=cv2.contourArea)\n                if cv2.contourArea(largest_contour) > 100:  # Only react to significant objects\n                    # Calculate the centroid\n                    M = cv2.moments(largest_contour)\n                    if M["m00"] != 0:\n                        cx = int(M["m10"] / M["m00"])\n                        image_center = self.latest_image.shape[1] / 2\n                        error = cx - image_center\n\n                        # Adjust angular velocity based on object position\n                        cmd.angular.z = -0.005 * error  # Negative for correct direction\n                        self.cmd_vel_pub.publish(cmd)\n                        self.get_logger().info(f"Detected red object, adjusting direction: {error:.2f}")\n\ndef main(args=None):\n    rclpy.init(args=args)\n    controller = GazeboRobotController()\n\n    try:\n        rclpy.spin(controller)\n    except KeyboardInterrupt:\n        controller.get_logger().info("Gazebo Robot Controller stopped by user")\n    finally:\n        controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"small-simulation",children:"Small Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Let's create a more advanced simulation example that demonstrates sensor fusion in Gazebo:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'# sensor_fusion_simulator.py\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, Point\nfrom sensor_msgs.msg import LaserScan, Imu, MagneticField\nfrom nav_msgs.msg import Odometry\nfrom std_msgs.msg import Float32, String\nimport numpy as np\nimport math\n\nclass SensorFusionSimulator(Node):\n    """\n    Demonstrates sensor fusion in Gazebo simulation using multiple sensor types\n    """\n    def __init__(self):\n        super().__init__(\'sensor_fusion_simulator\')\n\n        # Publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/simple_robot/cmd_vel\', 10)\n        self.fused_pose_pub = self.create_publisher(Point, \'/fused_pose\', 10)\n        self.status_pub = self.create_publisher(String, \'/sensor_fusion_status\', 10)\n\n        # Subscribers\n        self.odom_sub = self.create_subscription(Odometry, \'/simple_robot/odom\', self.odom_callback, 10)\n        self.scan_sub = self.create_subscription(LaserScan, \'/simple_robot/scan\', self.scan_callback, 10)\n        self.imu_sub = self.create_subscription(Imu, \'/simple_robot/imu\', self.imu_callback, 10)\n\n        # Timer for fusion loop\n        self.fusion_timer = self.create_timer(0.05, self.fusion_loop)\n\n        # Robot state estimation\n        self.position = Point()\n        self.velocity = Point()\n        self.orientation = 0.0  # yaw angle\n        self.angular_velocity = 0.0\n        self.linear_velocity = 0.0\n\n        # Sensor data storage\n        self.odom_data = None\n        self.scan_data = None\n        self.imu_data = None\n\n        # Kalman filter parameters (simplified)\n        self.position_uncertainty = 0.1\n        self.orientation_uncertainty = 0.1\n\n        # Fusion weights for different sensors\n        self.odom_weight = 0.7\n        self.imu_weight = 0.3\n\n        self.get_logger().info("Sensor Fusion Simulator initialized")\n\n    def odom_callback(self, msg):\n        """Process odometry data"""\n        self.odom_data = msg\n\n    def scan_callback(self, msg):\n        """Process laser scan data for obstacle detection and localization"""\n        self.scan_data = msg\n\n        # Process scan to detect obstacles and estimate position relative to known landmarks\n        # This is a simplified approach - in reality, this would involve more complex SLAM\n        front_ranges = msg.ranges[330:] + msg.ranges[:30]\n        front_ranges = [r for r in front_ranges if not np.isnan(r) and 0.1 < r < 10.0]\n\n        if front_ranges:\n            min_dist = min(front_ranges)\n            # If we know the world layout, we could estimate position based on distances to known objects\n            # For now, just log the information\n            self.get_logger().info(f"Closest obstacle: {min_dist:.2f}m")\n\n    def imu_callback(self, msg):\n        """Process IMU data"""\n        self.imu_data = msg\n\n        # Extract orientation from quaternion\n        # Simplified: just using z-axis rotation (yaw)\n        w = msg.orientation.w\n        z = msg.orientation.z\n        self.orientation = math.atan2(2.0 * (w * z), 1.0 - 2.0 * (z * z))\n\n        # Extract angular velocity\n        self.angular_velocity = msg.angular_velocity.z\n        self.linear_velocity = math.sqrt(\n            msg.linear_acceleration.x**2 +\n            msg.linear_acceleration.y**2\n        )\n\n    def fusion_loop(self):\n        """Main sensor fusion loop"""\n        fused_position = Point()\n\n        # If we have both odom and IMU data, perform simple fusion\n        if self.odom_data and self.imu_data:\n            # Position fusion (weighted average)\n            odom_x = self.odom_data.pose.pose.position.x\n            odom_y = self.odom_data.pose.pose.position.y\n\n            # Use IMU to predict position change since last odom\n            dt = 0.05  # timer period\n            dx = self.linear_velocity * math.cos(self.orientation) * dt\n            dy = self.linear_velocity * math.sin(self.orientation) * dt\n\n            # Fused position\n            fused_x = self.odom_weight * odom_x + self.imu_weight * (self.position.x + dx)\n            fused_y = self.odom_weight * odom_y + self.imu_weight * (self.position.y + dy)\n\n            fused_position.x = fused_x\n            fused_position.y = fused_y\n            fused_position.z = self.odom_data.pose.pose.position.z  # Use odom z for now\n\n            # Update our position estimate\n            self.position = fused_position\n\n            # Publish fused position\n            self.fused_pose_pub.publish(fused_position)\n\n            # Publish status\n            status_msg = String()\n            status_msg.data = f"Fused Pos: ({fused_position.x:.2f}, {fused_position.y:.2f}), " \\\n                             f"Ori: {self.orientation:.2f}, LinVel: {self.linear_velocity:.2f}m/s"\n            self.status_pub.publish(status_msg)\n        elif self.odom_data:\n            # If only odom is available, use that\n            self.position = self.odom_data.pose.pose.position\n            self.fused_pose_pub.publish(self.position)\n        elif self.imu_data:\n            # If only IMU is available, integrate\n            dt = 0.05\n            dx = self.linear_velocity * math.cos(self.orientation) * dt\n            dy = self.linear_velocity * math.sin(self.orientation) * dt\n\n            self.position.x += dx\n            self.position.y += dy\n\n            fused_position = self.position\n            self.fused_pose_pub.publish(fused_position)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    fusion_sim = SensorFusionSimulator()\n\n    try:\n        rclpy.spin(fusion_sim)\n    except KeyboardInterrupt:\n        fusion_sim.get_logger().info("Sensor Fusion Simulator stopped by user")\n    finally:\n        fusion_sim.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(e.h2,{id:"quick-recap",children:"Quick Recap"}),"\n",(0,s.jsx)(e.p,{children:"In this lesson, we've covered:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Gazebo Architecture"}),": Understanding the components of the Gazebo simulation environment"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"World Creation"}),": Creating simulation environments with objects and obstacles"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Robot Modeling"}),": Extending URDF with Gazebo-specific plugins and sensors"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sensor Integration"}),": Adding cameras, LIDAR, and IMU sensors to simulated robots"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Control Systems"}),": Connecting simulated robots to ROS 2 for control and interaction"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sensor Fusion"}),": Combining multiple sensor inputs for improved robot perception"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:'Gazebo provides a realistic physics simulation environment that serves as an essential "digital twin" for robotics development. It allows for safe, rapid prototyping and testing of robot behaviors before deployment to real hardware.'}),"\n",(0,s.jsx)(e.p,{children:"In the next lesson, we'll explore physics and collision modeling in more detail, including advanced material properties and realistic interaction modeling."})]})}function d(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(m,{...n})}):m(n)}},8453(n,e,i){i.d(e,{R:()=>a,x:()=>r});var o=i(6540);const s={},t=o.createContext(s);function a(n){const e=o.useContext(t);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),o.createElement(t.Provider,{value:e},n.children)}}}]);
"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[703],{7017(n,e,a){a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>t,toc:()=>_});const t=JSON.parse('{"id":"physical-ai/the-ai-robot-brain-nvidia-isaac/nav2-path-planning-humanoid","title":"Nav2 Path Planning for Humanoid Robots","description":"Overview","source":"@site/docs/physical-ai/the-ai-robot-brain-nvidia-isaac/nav2-path-planning-humanoid.md","sourceDirName":"physical-ai/the-ai-robot-brain-nvidia-isaac","slug":"/physical-ai/the-ai-robot-brain-nvidia-isaac/nav2-path-planning-humanoid","permalink":"/physical-ai-book/docs/physical-ai/the-ai-robot-brain-nvidia-isaac/nav2-path-planning-humanoid","draft":false,"unlisted":false,"editUrl":"https://github.com/arijh/physical-ai-book/tree/main/packages/create-docusaurus/templates/shared/docs/physical-ai/the-ai-robot-brain-nvidia-isaac/nav2-path-planning-humanoid.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Nav2 Path Planning for Humanoid Robots","title":"Nav2 Path Planning for Humanoid Robots"},"sidebar":"docs","previous":{"title":"Isaac ROS for VSLAM","permalink":"/physical-ai-book/docs/physical-ai/the-ai-robot-brain-nvidia-isaac/isaac-ros-vslam"},"next":{"title":"Introduction to Vision-Language-Action Integration","permalink":"/physical-ai-book/docs/physical-ai/vision-language-action-vla/introduction-to-vla-integration"}}');var o=a(4848),s=a(8453);const i={sidebar_label:"Nav2 Path Planning for Humanoid Robots",title:"Nav2 Path Planning for Humanoid Robots"},r="Nav2-based Path Planning for Humanoid Robots",l={},_=[{value:"Overview",id:"overview",level:2},{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Hands-on Steps",id:"hands-on-steps",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Small Simulation",id:"small-simulation",level:2},{value:"Quick Recap",id:"quick-recap",level:2},{value:"Summary of Chapter 4",id:"summary-of-chapter-4",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"nav2-based-path-planning-for-humanoid-robots",children:"Nav2-based Path Planning for Humanoid Robots"})}),"\n",(0,o.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(e.p,{children:"Navigation 2 (Nav2) is the latest navigation stack for ROS 2, providing state-of-the-art path planning and execution capabilities. When applied to humanoid robots, Nav2 requires special considerations due to their complex kinematics, balance requirements, and unique locomotion patterns. This lesson explores how to adapt Nav2 for humanoid robot navigation, including specialized planners, controllers, and safety considerations that account for the robot's bipedal nature."}),"\n",(0,o.jsx)(e.p,{children:"Humanoid robots present unique challenges for navigation systems due to their narrow support base, balance constraints, and complex movement patterns. Understanding how to configure and customize Nav2 for these requirements is crucial for developing effective autonomous humanoid robot navigation systems."}),"\n",(0,o.jsx)(e.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,o.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Configure Nav2 for humanoid robot kinematics and dynamics"}),"\n",(0,o.jsx)(e.li,{children:"Implement specialized path planners for bipedal locomotion"}),"\n",(0,o.jsx)(e.li,{children:"Set up safety and balance-aware navigation behaviors"}),"\n",(0,o.jsx)(e.li,{children:"Integrate whole-body planning with Nav2's framework"}),"\n",(0,o.jsx)(e.li,{children:"Adapt Nav2 for complex humanoid robot locomotion patterns"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"hands-on-steps",children:"Hands-on Steps"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Nav2 Configuration"}),": Set up Nav2 for humanoid robot parameters"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Specialized Planning"}),": Create planners that account for bipedal constraints"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Balance-Aware Control"}),": Implement balance-aware navigation behaviors"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Safety Integration"}),": Add humanoid-specific safety considerations"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Performance Testing"}),": Validate navigation on humanoid robot models"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Understanding of Nav2 architecture and components"}),"\n",(0,o.jsx)(e.li,{children:"Knowledge of humanoid robot kinematics and dynamics"}),"\n",(0,o.jsx)(e.li,{children:"Experience with Isaac Sim and ROS 2 navigation"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,o.jsx)(e.p,{children:"Let's start by creating a configuration file for Nav2 adapted for humanoid robots:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-yaml",children:'# humanoid_nav2_params.yaml\namcl:\n  ros__parameters:\n    use_sim_time: True\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_footprint"\n    beam_skip_distance: 0.5\n    beam_skip_error_threshold: 0.9\n    beam_skip_threshold: 0.3\n    do_beamskip: false\n    global_frame_id: "map"\n    lambda_short: 0.1\n    laser_likelihood_max_dist: 2.0\n    laser_max_range: 10.0\n    laser_min_range: -1.0\n    laser_model_type: "likelihood_field"\n    max_beams: 60\n    max_particles: 2000\n    min_particles: 500\n    odom_frame_id: "odom"\n    pf_err: 0.05\n    pf_z: 0.99\n    recovery_alpha_fast: 0.0\n    recovery_alpha_slow: 0.0\n    resample_interval: 1\n    robot_model_type: "nav2_amcl::DifferentialMotionModel"\n    save_pose_rate: 0.5\n    sigma_hit: 0.2\n    tf_broadcast: true\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.25\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.5\n    z_short: 0.05\n\namcl_map_client:\n  ros__parameters:\n    use_sim_time: True\n\namcl_rclcpp_node:\n  ros__parameters:\n    use_sim_time: True\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: True\n    enable_groot_monitoring: True\n    groot_zmq_publisher_port: 1666\n    groot_zmq_server_port: 1667\n    default_bt_xml_filename: "humanoid_nav2_default_bt.xml"\n    plugin_lib_names:\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_compute_path_through_poses_action_bt_node\n    - nav2_follow_path_action_bt_node\n    - nav2_spin_action_bt_node\n    - nav2_wait_action_bt_node\n    - nav2_assisted_teleop_action_bt_node\n    - nav2_back_up_action_bt_node\n    - nav2_drive_on_heading_bt_node\n    - nav2_clear_costmap_service_bt_node\n    - nav2_is_stuck_condition_bt_node\n    - nav2_goal_reached_condition_bt_node\n    - nav2_goal_updated_condition_bt_node\n    - nav2_initial_pose_received_condition_bt_node\n    - nav2_reinitialize_global_localization_service_bt_node\n    - nav2_rate_controller_bt_node\n    - nav2_distance_controller_bt_node\n    - nav2_speed_controller_bt_node\n    - nav2_truncate_path_action_bt_node\n    - nav2_truncate_path_local_action_bt_node\n    - nav2_goal_updater_node_bt_node\n    - nav2_recovery_node_bt_node\n    - nav2_pipeline_sequence_bt_node\n    - nav2_round_robin_node_bt_node\n    - nav2_transform_available_condition_bt_node\n    - nav2_time_expired_condition_bt_node\n    - nav2_path_expiring_timer_condition\n    - nav2_distance_traveled_condition_bt_node\n    - nav2_single_trigger_bt_node\n    - nav2_is_battery_low_condition_bt_node\n    - nav2_navigate_through_poses_action_bt_node\n    - nav2_navigate_to_pose_action_bt_node\n    - nav2_remove_passed_goals_action_bt_node\n    - nav2_planner_selector_bt_node\n    - nav2_controller_selector_bt_node\n    - nav2_goal_checker_selector_bt_node\n    - nav2_controller_cancel_bt_node\n    - nav2_path_longer_on_approach_bt_node\n    - nav2_wait_cancel_bt_node\n\nbt_navigator_rclcpp_node:\n  ros__parameters:\n    use_sim_time: True\n\ncontroller_server:\n  ros__parameters:\n    use_sim_time: True\n    controller_frequency: 20.0\n    min_x_velocity_threshold: 0.001\n    min_y_velocity_threshold: 0.5\n    min_theta_velocity_threshold: 0.001\n    failure_tolerance: 0.3\n    progress_checker_plugin: "progress_checker"\n    goal_checker_plugin: "goal_checker"\n    controller_plugins: ["FollowPath"]\n\n    # Humanoid-specific controller\n    FollowPath:\n      plugin: "nav2_mppi_controller::MPPICtrl"\n      time_steps: 32\n      control_freq: 20.0\n      horizon: 3.2\n      control_horizon: 3.2\n      velocity_scaling_factor: 0.8  # Conservative for humanoid balance\n      frequency: 20.0\n\n      # Humanoid-specific parameters\n      max_linear_speed: 0.3  # Slower for stability\n      min_linear_speed: 0.05\n      max_angular_speed: 0.5  # Limited for balance\n      min_angular_speed: 0.05\n\n      # Balance constraints\n      balance_margin: 0.1  # Safety margin for support polygon\n      step_size_limit: 0.2  # Maximum step size\n      step_duration: 0.8    # Time per step\n      zmp_margin: 0.05      # Zero Moment Point safety margin\n\n    progress_checker:\n      plugin: "nav2_controller::SimpleProgressChecker"\n      required_movement_radius: 0.5\n      movement_time_allowance: 10.0\n\n    goal_checker:\n      plugin: "nav2_controller::SimpleGoalChecker"\n      xy_goal_tolerance: 0.2  # Larger for humanoid stepping accuracy\n      yaw_goal_tolerance: 0.2\n      stateful: True\n\nlocal_costmap:\n  local_costmap:\n    ros__parameters:\n      update_frequency: 5.0\n      publish_frequency: 2.0\n      global_frame: "odom"\n      robot_base_frame: "base_footprint"\n      use_sim_time: True\n      rolling_window: true\n      width: 6\n      height: 6\n      resolution: 0.05\n      robot_radius: 0.3  # Larger radius for humanoid safety\n      plugins: ["voxel_layer", "inflation_layer"]\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.55\n      voxel_layer:\n        plugin: "nav2_costmap_2d::VoxelLayer"\n        enabled: True\n        publish_voxel_map: True\n        origin_z: 0.0\n        z_resolution: 0.2\n        z_voxels: 10\n        max_obstacle_height: 2.0\n        mark_threshold: 0\n        observation_sources: "scan"\n        scan:\n          topic: "/humanoid_robot/scan"\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n  local_costmap_client:\n    ros__parameters:\n      use_sim_time: True\n  local_costmap_rclcpp_node:\n    ros__parameters:\n      use_sim_time: True\n\nglobal_costmap:\n  global_costmap:\n    ros__parameters:\n      update_frequency: 1.0\n      publish_frequency: 1.0\n      global_frame: "map"\n      robot_base_frame: "base_footprint"\n      use_sim_time: True\n      robot_radius: 0.3\n      resolution: 0.05\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\n      obstacle_layer:\n        plugin: "nav2_costmap_2d::ObstacleLayer"\n        enabled: True\n        observation_sources: "scan"\n        scan:\n          topic: "/humanoid_robot/scan"\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n      static_layer:\n        plugin: "nav2_costmap_2d::StaticLayer"\n        map_subscribe_transient_local: True\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.6\n  global_costmap_client:\n    ros__parameters:\n      use_sim_time: True\n  global_costmap_rclcpp_node:\n    ros__parameters:\n      use_sim_time: True\n\nplanner_server:\n  ros__parameters:\n    expected_planner_frequency: 20.0\n    use_sim_time: True\n    planner_plugins: ["GridBased"]\n\n    # Humanoid-specific planner\n    GridBased:\n      plugin: "humanoid_nav2_plugins::HumanoidGridBasedPlanner"\n      tolerance: 0.5\n      use_astar: false\n      allow_unknown: true\n      max_iterations: 10000\n      max_on_approach_iterations: 1000\n\n      # Humanoid-specific parameters\n      min_distance_from_wall: 0.4  # Extra safety for humanoid width\n      step_size: 0.1              # Conservative step size\n      step_height: 0.15           # Maximum step height\n      foot_separation: 0.3        # Distance between feet\n      support_polygon_buffer: 0.1 # Buffer for support polygon\n\n      # Balance-aware planning\n      balance_constraint_weight: 10.0\n      zmp_constraint_weight: 5.0\n      com_height: 0.8             # Center of mass height for humanoid\n\nsmoother_server:\n  ros__parameters:\n    use_sim_time: True\n    smoother_plugins: ["simple_smoother"]\n    simple_smoother:\n      plugin: "nav2_smoother::SimpleSmoother"\n      tolerance: 1.0e-10\n      max_its: 1000\n      do_refinement: True\n\nbehavior_server:\n  ros__parameters:\n    costmap_topic: global_costmap/costmap_raw\n    footprint_topic: global_costmap/published_footprint\n    cycle_frequency: 10.0\n    behavior_plugins: ["spin", "backup", "wait", "assisted_teleop"]\n    spin:\n      plugin: "nav2_behaviors::Spin"\n      server_timeout: 20\n      sim_frequency: 20\n      angle_thresh: 0.785\n      angle_offset: 1.57\n      scale_vel: 0.5\n    backup:\n      plugin: "nav2_behaviors::BackUp"\n      server_timeout: 20\n      sim_frequency: 20\n      distance: 0.15  # Shorter backup distance for humanoid safety\n      forward_sampling_distance: 0.05\n      max_vel: 0.025\n    wait:\n      plugin: "nav2_behaviors::Wait"\n      server_timeout: 20\n      sim_frequency: 20\n      duration: 1.0\n    assisted_teleop:\n      plugin: "nav2_behaviors::AssistedTeleop"\n      server_timeout: 20\n      sim_frequency: 20\n      smooth_move: true\n      use_duration: false\n      duration: 2.0\n\nwaypoint_follower:\n  ros__parameters:\n    loop_rate: 20\n    stop_on_failure: false\n    waypoint_task_executor_plugin: "wait_at_waypoint"\n    wait_at_waypoint:\n      plugin: "nav2_waypoint_follower::WaitAtWaypoint"\n      enabled: true\n      waypoint_pause_duration: 0\n'})}),"\n",(0,o.jsx)(e.p,{children:"Now let's create a custom path planner that's aware of humanoid balance constraints:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# humanoid_path_planner.py\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom sensor_msgs.msg import LaserScan\nfrom std_msgs.msg import String\nfrom builtin_interfaces.msg import Duration\nfrom nav2_msgs.action import ComputePathToPose\nfrom nav2_msgs.srv import GetCostmap\nfrom nav2_util.lifecycle_node import LifecycleNode\nfrom nav2_costmap_2d.costmap_2d_ros import Costmap2DROS\nfrom nav2_costmap_2d.costmap_2d import Costmap2D\nfrom geometry_msgs.msg import PoseWithCovarianceStamped\nimport numpy as np\nimport math\nfrom scipy.spatial.distance import cdist\nimport heapq\n\nclass HumanoidGridBasedPlanner(LifecycleNode):\n    """\n    Custom path planner for humanoid robots with balance constraints\n    """\n    def __init__(self, name):\n        super().__init__(name)\n        self.name = name\n        self.costmap_ros = None\n        self.costmap = None\n        self.global_frame = \'map\'\n        self.robot_base_frame = \'base_footprint\'\n        self.planner_frequency = 20.0\n\n        # Humanoid-specific parameters\n        self.min_distance_from_wall = 0.4\n        self.step_size = 0.1\n        self.step_height = 0.15\n        self.foot_separation = 0.3\n        self.support_polygon_buffer = 0.1\n        self.balance_constraint_weight = 10.0\n        self.zmp_constraint_weight = 5.0\n        self.com_height = 0.8\n\n        # Path smoothing parameters\n        self.smoothing_weight = 0.5\n        self.curvature_weight = 0.3\n\n    def configure(self, node, plugin_name, plugin_type):\n        """Configure the planner"""\n        self.logger.info(f"Configuring {plugin_name}")\n\n        # Get costmap\n        self.costmap_ros = node.get_parameter(\'global_costmap\').value\n        self.global_frame = self.costmap_ros.get_parameter(\'global_frame\').value\n\n        # Get humanoid-specific parameters\n        self.min_distance_from_wall = node.get_parameter(\'min_distance_from_wall\').value\n        self.step_size = node.get_parameter(\'step_size\').value\n        self.com_height = node.get_parameter(\'com_height\').value\n        self.balance_constraint_weight = node.get_parameter(\'balance_constraint_weight\').value\n\n        self.logger.info(f"{plugin_name} configured successfully")\n\n    def activate(self):\n        """Activate the planner"""\n        self.logger.info(f"{self.name} activated")\n        return True\n\n    def deactivate(self):\n        """Deactivate the planner"""\n        self.logger.info(f"{self.name} deactivated")\n        return True\n\n    def cleanup(self):\n        """Clean up the planner"""\n        self.logger.info(f"{self.name} cleaned up")\n        return True\n\n    def create_plan(self, start, goal, tolerance):\n        """\n        Create a path from start to goal considering humanoid constraints\n        """\n        self.get_logger().info(f"Creating plan from ({start.pose.position.x}, {start.pose.position.y}) "\n                              f"to ({goal.pose.position.x}, {goal.pose.position.y})")\n\n        # Get current costmap\n        costmap = self.costmap_ros.get_costmap()\n\n        # Convert start and goal to costmap coordinates\n        start_x = int((start.pose.position.x - costmap.getOriginX()) / costmap.getResolution())\n        start_y = int((start.pose.position.y - costmap.getOriginY()) / costmap.getResolution())\n\n        goal_x = int((goal.pose.position.x - costmap.getOriginX()) / costmap.getResolution())\n        goal_y = int((goal.pose.position.y - costmap.getOriginY()) / costmap.getResolution())\n\n        # Check if start and goal are valid\n        if not self.is_valid_cell(costmap, start_x, start_y) or not self.is_valid_cell(costmap, goal_x, goal_y):\n            self.get_logger().warn("Start or goal position is not valid")\n            return self.create_empty_path()\n\n        # Plan path using modified A* with humanoid constraints\n        path_cells = self.humanoid_astar(costmap, (start_x, start_y), (goal_x, goal_y))\n\n        if not path_cells:\n            self.get_logger().warn("No valid path found")\n            return self.create_empty_path()\n\n        # Convert path cells to world coordinates\n        world_path = self.cells_to_world_path(path_cells, costmap)\n\n        # Apply humanoid-specific path smoothing\n        smoothed_path = self.humanoid_path_smoothing(world_path)\n\n        # Create and return path message\n        path_msg = Path()\n        path_msg.header.frame_id = self.global_frame\n        path_msg.header.stamp = self.get_clock().now().to_msg()\n\n        for point in smoothed_path:\n            pose = PoseStamped()\n            pose.header.frame_id = self.global_frame\n            pose.header.stamp = self.get_clock().now().to_msg()\n            pose.pose.position.x = point[0]\n            pose.pose.position.y = point[1]\n            pose.pose.position.z = 0.0\n            # Set orientation to point towards next point\n            if len(smoothed_path) > 1 and np.array_equal(point, smoothed_path[0]):\n                # First point - look towards second point\n                dx = smoothed_path[1][0] - point[0]\n                dy = smoothed_path[1][1] - point[1]\n                yaw = math.atan2(dy, dx)\n                pose.pose.orientation.z = math.sin(yaw / 2)\n                pose.pose.orientation.w = math.cos(yaw / 2)\n            elif np.array_equal(point, smoothed_path[-1]):\n                # Last point - keep orientation from previous\n                pass\n            else:\n                # Intermediate points - look towards next\n                idx = smoothed_path.index(list(point) if isinstance(point, np.ndarray) else point)\n                if idx < len(smoothed_path) - 1:\n                    dx = smoothed_path[idx + 1][0] - point[0]\n                    dy = smoothed_path[idx + 1][1] - point[1]\n                    yaw = math.atan2(dy, dx)\n                    pose.pose.orientation.z = math.sin(yaw / 2)\n                    pose.pose.orientation.w = math.cos(yaw / 2)\n\n            path_msg.poses.append(pose)\n\n        self.get_logger().info(f"Path created with {len(path_msg.poses)} waypoints")\n        return path_msg\n\n    def is_valid_cell(self, costmap, x, y):\n        """Check if a cell is valid for humanoid navigation"""\n        # Check bounds\n        if x < 0 or x >= costmap.getSizeInCellsX() or y < 0 or y >= costmap.getSizeInCellsY():\n            return False\n\n        # Get cost\n        cost = costmap.getCost(x, y)\n\n        # Check if cell is in lethal obstacle or unknown (but allow unknown if configured)\n        lethal_cost = costmap.getCostmap().LETHAL_OBSTACLE\n        unknown_cost = costmap.getCostmap().NO_INFORMATION\n\n        # Humanoid-specific: need to maintain safety distance from obstacles\n        if cost >= lethal_cost * 0.9:  # 90% of lethal cost is too dangerous\n            return False\n\n        return True\n\n    def humanoid_astar(self, costmap, start, goal):\n        """A* algorithm modified for humanoid robot constraints"""\n        # Heuristic function\n        def heuristic(a, b):\n            return math.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n\n        # Priority queue: (f_score, g_score, position)\n        open_set = [(0, 0, start)]\n        came_from = {}\n        g_score = {start: 0}\n        f_score = {start: heuristic(start, goal)}\n\n        # Keep track of visited cells to avoid cycles\n        closed_set = set()\n\n        # 8-directional movement (for smoother paths)\n        neighbors = [\n            (-1, -1), (-1, 0), (-1, 1),\n            (0, -1),           (0, 1),\n            (1, -1),  (1, 0),  (1, 1)\n        ]\n\n        while open_set:\n            current = heapq.heappop(open_set)[2]\n\n            if current == goal:\n                # Reconstruct path\n                path = []\n                while current in came_from:\n                    path.append(current)\n                    current = came_from[current]\n                path.append(start)\n                path.reverse()\n                return path\n\n            closed_set.add(current)\n\n            for dx, dy in neighbors:\n                neighbor = (current[0] + dx, current[1] + dy)\n\n                # Check bounds\n                if (neighbor[0] < 0 or neighbor[0] >= costmap.getSizeInCellsX() or\n                    neighbor[1] < 0 or neighbor[1] >= costmap.getSizeInCellsY()):\n                    continue\n\n                # Skip if already visited\n                if neighbor in closed_set:\n                    continue\n\n                # Check if valid for humanoid\n                if not self.is_valid_cell(costmap, neighbor[0], neighbor[1]):\n                    continue\n\n                # Calculate tentative g_score\n                # For diagonal moves, use longer distance\n                move_cost = math.sqrt(2) if dx != 0 and dy != 0 else 1\n\n                # Add humanoid-specific cost based on balance constraints\n                balance_cost = self.calculate_balance_cost(costmap, neighbor, goal)\n                tentative_g_score = g_score[current] + move_cost + balance_cost\n\n                # If this path to neighbor is better\n                if neighbor not in g_score or tentative_g_score < g_score[neighbor]:\n                    came_from[neighbor] = current\n                    g_score[neighbor] = tentative_g_score\n                    f_score[neighbor] = tentative_g_score + heuristic(neighbor, goal)\n\n                    heapq.heappush(open_set, (f_score[neighbor], g_score[neighbor], neighbor))\n\n        # No path found\n        return []\n\n    def calculate_balance_cost(self, costmap, cell, goal):\n        """Calculate additional cost based on humanoid balance constraints"""\n        # This is a simplified balance cost calculation\n        # In reality, this would involve complex ZMP (Zero Moment Point) calculations\n\n        # Get real-world coordinates\n        resolution = costmap.getResolution()\n        world_x = costmap.getOriginX() + cell[0] * resolution\n        world_y = costmap.getOriginY() + cell[1] * resolution\n\n        # Calculate distance to goal (for goal-direction bias)\n        goal_x = costmap.getOriginX() + goal[0] * resolution\n        goal_y = costmap.getOriginY() + goal[1] * resolution\n        dist_to_goal = math.sqrt((world_x - goal_x)**2 + (world_y - goal_y)**2)\n\n        # Check local terrain for roughness (simplified)\n        roughness_cost = 0\n        for dx in [-1, 0, 1]:\n            for dy in [-1, 0, 1]:\n                neighbor = (cell[0] + dx, cell[1] + dy)\n                if (0 <= neighbor[0] < costmap.getSizeInCellsX() and\n                    0 <= neighbor[1] < costmap.getSizeInCellsY()):\n                    neighbor_cost = costmap.getCost(neighbor[0], neighbor[1])\n                    # Higher cost for areas with obstacles nearby\n                    if neighbor_cost > 50:  # Some threshold\n                        roughness_cost += 0.1\n\n        # Balance cost is higher for areas with obstacles nearby\n        # and slightly biased towards goal direction\n        balance_cost = roughness_cost * self.balance_constraint_weight\n        goal_bias = max(0, 1 - dist_to_goal / 10.0) * 0.1  # Slightly prefer goal direction\n\n        return balance_cost + goal_bias\n\n    def cells_to_world_path(self, path_cells, costmap):\n        """Convert path from cell coordinates to world coordinates"""\n        resolution = costmap.getResolution()\n        origin_x = costmap.getOriginX()\n        origin_y = costmap.getOriginY()\n\n        world_path = []\n        for cell_x, cell_y in path_cells:\n            world_x = origin_x + (cell_x + 0.5) * resolution\n            world_y = origin_y + (cell_y + 0.5) * resolution\n            world_path.append([world_x, world_y])\n\n        return np.array(world_path)\n\n    def humanoid_path_smoothing(self, path):\n        """Apply smoothing that respects humanoid movement constraints"""\n        if len(path) < 3:\n            return path\n\n        # Apply smoothing with constraints\n        smoothed_path = [path[0]]  # Always keep start point\n\n        i = 0\n        while i < len(path) - 1:\n            # Look ahead to find a point that can be directly reached with smooth motion\n            j = i + 1\n            while j < len(path) - 1:\n                # Check if path from path[i] to path[j] is smooth enough for humanoid\n                if self.is_smooth_enough(path[i], path[j], path[min(j+1, len(path)-1)]):\n                    j += 1\n                else:\n                    break\n\n            # Add the furthest smooth point we found\n            smoothed_path.append(path[j-1])\n            i = j - 1\n\n        # Always add the goal point\n        if not np.array_equal(smoothed_path[-1], path[-1]):\n            smoothed_path.append(path[-1])\n\n        return np.array(smoothed_path)\n\n    def is_smooth_enough(self, p1, p2, p3):\n        """Check if the path segment through these points is smooth enough for humanoid"""\n        # Calculate curvature between three points\n        # For simplicity, use a basic curvature calculation\n        if np.array_equal(p1, p2) or np.array_equal(p2, p3):\n            return True\n\n        # Calculate angles to check for sharp turns\n        v1 = p2 - p1\n        v2 = p3 - p2\n\n        # Calculate angle between vectors\n        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n        angle = np.arccos(np.clip(cos_angle, -1, 1))\n\n        # Humanoids can\'t make very sharp turns, so limit the angle\n        max_angle = math.radians(45)  # 45 degrees maximum\n\n        return angle < max_angle\n\n    def create_empty_path(self):\n        """Create an empty path message"""\n        path_msg = Path()\n        path_msg.header.frame_id = self.global_frame\n        path_msg.header.stamp = self.get_clock().now().to_msg()\n        return path_msg\n\n# Node for testing the planner\nclass HumanoidPathPlannerTestNode(Node):\n    """\n    Test node for the humanoid path planner\n    """\n    def __init__(self):\n        super().__init__(\'humanoid_path_planner_test\')\n\n        # Publishers\n        self.path_pub = self.create_publisher(Path, \'/humanoid_plan\', 10)\n        self.status_pub = self.create_publisher(String, \'/humanoid_planner_status\', 10)\n\n        # Timers\n        self.test_timer = self.create_timer(5.0, self.test_planning)\n\n        # Test parameters\n        self.start_pose = PoseStamped()\n        self.start_pose.pose.position.x = 0.0\n        self.start_pose.pose.position.y = 0.0\n\n        self.goal_pose = PoseStamped()\n        self.goal_pose.pose.position.x = 5.0\n        self.goal_pose.pose.position.y = 5.0\n\n        self.get_logger().info("Humanoid Path Planner Test Node initialized")\n\n    def test_planning(self):\n        """Test the path planning functionality"""\n        self.get_logger().info(f"Testing path planning from ({self.start_pose.pose.position.x}, {self.start_pose.pose.position.y}) "\n                              f"to ({self.goal_pose.pose.position.x}, {self.goal_pose.pose.position.y})")\n\n        # In a real implementation, we would call the planner service here\n        # For this example, we\'ll simulate the planner\n        self.simulate_planning()\n\n    def simulate_planning(self):\n        """Simulate planning to show expected behavior"""\n        # Create a sample path (this would be generated by the actual planner)\n        path_msg = Path()\n        path_msg.header.frame_id = \'map\'\n        path_msg.header.stamp = self.get_clock().now().to_msg()\n\n        # Create a curved path to demonstrate humanoid-aware planning\n        for i in range(20):\n            t = i / 19.0  # Parameter from 0 to 1\n            x = t * 5.0  # From 0 to 5\n            y = t * 5.0 + 0.5 * math.sin(t * 3)  # Slight curve\n            theta = math.atan2(5.0 + 0.5 * 3 * math.cos(t * 3), 5.0)  # Orientation\n\n            pose = PoseStamped()\n            pose.header.frame_id = \'map\'\n            pose.header.stamp = self.get_clock().now().to_msg()\n            pose.pose.position.x = x\n            pose.pose.position.y = y\n            pose.pose.position.z = 0.0\n            pose.pose.orientation.z = math.sin(theta / 2)\n            pose.pose.orientation.w = math.cos(theta / 2)\n\n            path_msg.poses.append(pose)\n\n        self.path_pub.publish(path_msg)\n\n        status_msg = String()\n        status_msg.data = f"Test path published with {len(path_msg.poses)} waypoints"\n        self.status_pub.publish(status_msg)\n\n        self.get_logger().info(f"Test path published with {len(path_msg.poses)} waypoints")\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    # For testing, create the test node\n    test_node = HumanoidPathPlannerTestNode()\n\n    try:\n        rclpy.spin(test_node)\n    except KeyboardInterrupt:\n        test_node.get_logger().info("Humanoid Path Planner Test Node stopped by user")\n    finally:\n        test_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.p,{children:"Now let's create a humanoid-specific controller that works with Nav2:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# humanoid_controller.py\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, PoseStamped, Point\nfrom nav_msgs.msg import Path, Odometry\nfrom sensor_msgs.msg import Imu, LaserScan\nfrom std_msgs.msg import String, Float64\nfrom tf2_ros import TransformListener, Buffer\nfrom tf2_geometry_msgs import do_transform_pose\nimport numpy as np\nimport math\nfrom scipy.spatial.distance import cdist\nfrom geometry_msgs.msg import Vector3\n\nclass HumanoidController(Node):\n    """\n    Specialized controller for humanoid robot navigation\n    Implements balance-aware control and bipedal locomotion patterns\n    """\n    def __init__(self):\n        super().__init__(\'humanoid_controller\')\n\n        # Publishers\n        self.cmd_vel_pub = self.create_publisher(Twist, \'/humanoid_robot/cmd_vel\', 10)\n        self.status_pub = self.create_publisher(String, \'/humanoid_controller/status\', 10)\n        self.balance_pub = self.create_publisher(Float64, \'/humanoid_controller/balance_metric\', 10)\n\n        # Subscribers\n        self.path_sub = self.create_subscription(Path, \'/humanoid_plan\', self.path_callback, 10)\n        self.odom_sub = self.create_subscription(Odometry, \'/humanoid_robot/odom\', self.odom_callback, 10)\n        self.imu_sub = self.create_subscription(Imu, \'/humanoid_robot/imu\', self.imu_callback, 10)\n        self.scan_sub = self.create_subscription(LaserScan, \'/humanoid_robot/scan\', self.scan_callback, 10)\n\n        # Timers\n        self.control_timer = self.create_timer(0.05, self.control_loop)  # 20 Hz\n\n        # TF\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Robot state\n        self.current_pose = None\n        self.current_twist = None\n        self.current_imu = None\n        self.path = []\n        self.current_path_index = 0\n        self.path_following_active = False\n\n        # Controller parameters\n        self.linear_vel_limit = 0.3  # Conservative for balance\n        self.angular_vel_limit = 0.5\n        self.lookahead_distance = 0.5\n        self.arrival_threshold = 0.2\n        self.orientation_threshold = 0.2\n\n        # Balance control parameters\n        self.com_height = 0.8  # Center of mass height\n        self.balance_margin = 0.1  # Safety margin for support polygon\n        self.zmp_tolerance = 0.05  # Zero Moment Point tolerance\n\n        # Locomotion pattern parameters\n        self.step_height = 0.05\n        self.step_duration = 0.8\n        self.swing_phase_ratio = 0.3  # 30% of step for swing phase\n\n        # PID controllers\n        self.linear_pid = {\n            \'kp\': 1.0,\n            \'ki\': 0.1,\n            \'kd\': 0.05,\n            \'error_sum\': 0.0,\n            \'last_error\': 0.0\n        }\n\n        self.angular_pid = {\n            \'kp\': 2.0,\n            \'ki\': 0.2,\n            \'kd\': 0.1,\n            \'error_sum\': 0.0,\n            \'last_error\': 0.0\n        }\n\n        self.get_logger().info("Humanoid Controller initialized")\n\n    def path_callback(self, msg):\n        """Receive path and prepare for following"""\n        self.path = msg.poses\n        self.current_path_index = 0\n        self.path_following_active = True\n\n        self.get_logger().info(f"Received path with {len(self.path)} waypoints")\n\n    def odom_callback(self, msg):\n        """Update current pose from odometry"""\n        self.current_pose = msg.pose.pose\n        self.current_twist = msg.twist.twist\n\n    def imu_callback(self, msg):\n        """Update IMU data for balance control"""\n        self.current_imu = msg\n\n    def scan_callback(self, msg):\n        """Process laser scan for obstacle avoidance"""\n        # Check for obstacles in path\n        if self.path_following_active and len(self.path) > 0:\n            self.check_path_clearance(msg)\n\n    def check_path_clearance(self, scan_msg):\n        """Check if path is clear of obstacles"""\n        # Simple implementation - check if there are obstacles too close in front\n        front_ranges = scan_msg.ranges[330:] + scan_msg.ranges[:30]  # \xb130 degrees\n        front_ranges = [r for r in front_ranges if not math.isnan(r) and 0.1 < r < 3.0]\n\n        if front_ranges:\n            min_range = min(front_ranges)\n            if min_range < 0.5:  # Obstacle too close\n                self.path_following_active = False\n                self.get_logger().warn(f"Path blocked! Minimum range: {min_range:.2f}m")\n\n    def compute_control_command(self):\n        """Compute control command based on current state and path"""\n        if not self.path_following_active or not self.path or not self.current_pose:\n            return Twist()\n\n        # Find next target point along path\n        target_point = self.get_next_target_point()\n        if target_point is None:\n            # Check if we\'re near the end\n            last_point = self.path[-1].pose.position\n            current_pos = self.current_pose.position\n            dist_to_goal = math.sqrt(\n                (current_pos.x - last_point.x)**2 +\n                (current_pos.y - last_point.y)**2\n            )\n\n            if dist_to_goal < self.arrival_threshold:\n                # Reached goal\n                self.path_following_active = False\n                self.get_logger().info("Reached goal position")\n                return Twist()  # Stop\n            else:\n                # Can\'t find target, stop\n                self.get_logger().warn("Could not find target point on path")\n                return Twist()\n\n        # Calculate desired velocity towards target\n        dx = target_point.x - self.current_pose.position.x\n        dy = target_point.y - self.current_pose.position.y\n        distance_to_target = math.sqrt(dx**2 + dy**2)\n\n        # Calculate desired orientation\n        desired_yaw = math.atan2(dy, dx)\n\n        # Get current orientation\n        current_yaw = math.atan2(\n            2 * (self.current_pose.orientation.w * self.current_pose.orientation.z +\n                 self.current_pose.orientation.x * self.current_pose.orientation.y),\n            1 - 2 * (self.current_pose.orientation.y**2 + self.current_pose.orientation.z**2)\n        )\n\n        # Calculate orientation error\n        orientation_error = math.atan2(math.sin(desired_yaw - current_yaw),\n                                      math.cos(desired_yaw - current_yaw))\n\n        # Apply PID control for linear velocity\n        linear_error = distance_to_target\n        self.linear_pid[\'error_sum\'] += linear_error * 0.05  # dt = 0.05s\n        linear_derivative = (linear_error - self.linear_pid[\'last_error\']) / 0.05\n        linear_output = (self.linear_pid[\'kp\'] * linear_error +\n                        self.linear_pid[\'ki\'] * self.linear_pid[\'error_sum\'] +\n                        self.linear_pid[\'kd\'] * linear_derivative)\n\n        self.linear_pid[\'last_error\'] = linear_error\n\n        # Limit linear velocity\n        linear_vel = max(-self.linear_vel_limit, min(self.linear_vel_limit, linear_output))\n\n        # Apply PID control for angular velocity\n        angular_error = orientation_error\n        self.angular_pid[\'error_sum\'] += angular_error * 0.05  # dt = 0.05s\n        angular_derivative = (angular_error - self.angular_pid[\'last_error\']) / 0.05\n        angular_output = (self.angular_pid[\'kp\'] * angular_error +\n                         self.angular_pid[\'ki\'] * self.angular_pid[\'error_sum\'] +\n                         self.angular_pid[\'kd\'] * angular_derivative)\n\n        self.angular_pid[\'last_error\'] = angular_error\n\n        # Limit angular velocity\n        angular_vel = max(-self.angular_vel_limit, min(self.angular_vel_limit, angular_output))\n\n        # Balance-aware adjustments\n        if self.current_imu:\n            # Use IMU data to adjust for balance\n            roll = math.atan2(\n                2 * (self.current_imu.orientation.w * self.current_imu.orientation.x -\n                     self.current_imu.orientation.y * self.current_imu.orientation.z),\n                1 - 2 * (self.current_imu.orientation.x**2 + self.current_imu.orientation.y**2)\n            )\n            pitch = math.asin(\n                2 * (self.current_imu.orientation.w * self.current_imu.orientation.y +\n                     self.current_imu.orientation.x * self.current_imu.orientation.z)\n            )\n\n            # If robot is tilting too much, reduce speed\n            tilt_magnitude = math.sqrt(roll**2 + pitch**2)\n            if tilt_magnitude > 0.1:  # 0.1 rad = ~5.7 degrees\n                safety_factor = max(0.1, 1.0 - tilt_magnitude)  # Reduce speed based on tilt\n                linear_vel *= safety_factor\n                angular_vel *= safety_factor\n\n        # Create and return command\n        cmd = Twist()\n        cmd.linear.x = linear_vel\n        cmd.angular.z = angular_vel\n\n        return cmd\n\n    def get_next_target_point(self):\n        """Find the next point on the path to navigate towards"""\n        if not self.current_pose or not self.path:\n            return None\n\n        # Find the point on the path that is closest to the current position\n        current_pos = np.array([self.current_pose.position.x, self.current_pose.position.y])\n\n        # Look for the closest point on the path\n        min_distance = float(\'inf\')\n        closest_idx = self.current_path_index\n\n        for i in range(self.current_path_index, len(self.path)):\n            path_pos = np.array([self.path[i].pose.position.x, self.path[i].pose.position.y])\n            distance = np.linalg.norm(current_pos - path_pos)\n\n            if distance < min_distance:\n                min_distance = distance\n                closest_idx = i\n\n        # Now find a lookahead point\n        lookahead_point = None\n        for i in range(closest_idx, len(self.path)):\n            path_pos = np.array([self.path[i].pose.position.x, self.path[i].pose.position.y])\n            distance = np.linalg.norm(current_pos - path_pos)\n\n            if distance >= self.lookahead_distance:\n                lookahead_point = self.path[i].pose.position\n                self.current_path_index = i\n                break\n\n        # If no point is far enough, use the last point\n        if lookahead_point is None and len(self.path) > 0:\n            lookahead_point = self.path[-1].pose.position\n\n        return lookahead_point\n\n    def calculate_balance_metric(self):\n        """Calculate a metric representing how balanced the robot is"""\n        if not self.current_imu:\n            return 0.5  # Return neutral value if no IMU data\n\n        # Calculate tilt angles from IMU\n        roll = math.atan2(\n            2 * (self.current_imu.orientation.w * self.current_imu.orientation.x -\n                 self.current_imu.orientation.y * self.current_imu.orientation.z),\n            1 - 2 * (self.current_imu.orientation.x**2 + self.current_imu.orientation.y**2)\n        )\n        pitch = math.asin(\n            2 * (self.current_imu.orientation.w * self.current_imu.orientation.y +\n                 self.current_imu.orientation.x * self.current_imu.orientation.z)\n        )\n\n        # Calculate tilt magnitude\n        tilt_magnitude = math.sqrt(roll**2 + pitch**2)\n\n        # Convert to balance metric (0.0 = unbalanced, 1.0 = perfectly balanced)\n        max_acceptable_tilt = 0.2  # 0.2 rad = ~11.5 degrees\n        balance_metric = max(0.0, min(1.0, 1.0 - (tilt_magnitude / max_acceptable_tilt)))\n\n        return balance_metric\n\n    def control_loop(self):\n        """Main control loop"""\n        cmd = self.compute_control_command()\n\n        # Publish command\n        self.cmd_vel_pub.publish(cmd)\n\n        # Calculate and publish balance metric\n        balance_metric = self.calculate_balance_metric()\n        balance_msg = Float64()\n        balance_msg.data = balance_metric\n        self.balance_pub.publish(balance_metric)\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = f"PathIdx: {self.current_path_index}, Cmd: ({cmd.linear.x:.2f}, {cmd.angular.z:.2f}), " \\\n                         f"Balance: {balance_metric:.2f}, Active: {self.path_following_active}"\n        self.status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    controller = HumanoidController()\n\n    try:\n        rclpy.spin(controller)\n    except KeyboardInterrupt:\n        controller.get_logger().info("Humanoid Controller stopped by user")\n    finally:\n        controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"small-simulation",children:"Small Simulation"}),"\n",(0,o.jsx)(e.p,{children:"Let's create a simulation environment that demonstrates the humanoid navigation system:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# humanoid_navigation_simulator.py\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, Pose, Point\nfrom nav_msgs.msg import Path, Odometry\nfrom sensor_msgs.msg import LaserScan, Imu\nfrom std_msgs.msg import String\nfrom tf2_ros import TransformBroadcaster\nfrom geometry_msgs.msg import TransformStamped\nimport numpy as np\nimport math\n\nclass HumanoidNavigationSimulator(Node):\n    """\n    Simulation environment for humanoid navigation\n    Demonstrates the interaction between Nav2 and humanoid-specific controllers\n    """\n    def __init__(self):\n        super().__init__(\'humanoid_navigation_simulator\')\n\n        # Publishers\n        self.odom_pub = self.create_publisher(Odometry, \'/humanoid_robot/odom\', 10)\n        self.scan_pub = self.create_publisher(LaserScan, \'/humanoid_robot/scan\', 10)\n        self.imu_pub = self.create_publisher(Imu, \'/humanoid_robot/imu\', 10)\n        self.status_pub = self.create_publisher(String, \'/navigation_sim_status\', 10)\n\n        # Subscribers\n        self.cmd_vel_sub = self.create_subscription(Twist, \'/humanoid_robot/cmd_vel\', self.cmd_vel_callback, 10)\n\n        # TF broadcaster\n        self.tf_broadcaster = TransformBroadcaster(self)\n\n        # Timers\n        self.sim_timer = self.create_timer(0.05, self.simulation_step)  # 20 Hz\n        self.sensor_timer = self.create_timer(0.1, self.publish_sensors)  # 10 Hz\n\n        # Robot state\n        self.position = np.array([0.0, 0.0, 0.0])\n        self.orientation = np.array([0.0, 0.0, 0.0, 1.0])  # x, y, z, w\n        self.linear_velocity = 0.0\n        self.angular_velocity = 0.0\n        self.cmd_twist = Twist()\n\n        # Simulation parameters\n        self.sim_time = 0.0\n        self.robot_radius = 0.3\n        self.com_height = 0.8  # Center of mass height\n\n        # Environment setup\n        self.obstacles = [\n            {\'position\': np.array([2.0, 1.0]), \'radius\': 0.5},\n            {\'position\': np.array([3.0, -1.0]), \'radius\': 0.4},\n            {\'position\': np.array([0.0, 3.0]), \'radius\': 0.6},\n        ]\n\n        # Balance simulation parameters\n        self.balance_state = 0.0  # -1.0 to 1.0, where 0.0 is perfectly balanced\n        self.balance_damping = 0.95\n        self.balance_noise = 0.01\n\n        self.get_logger().info("Humanoid Navigation Simulator initialized")\n\n    def cmd_vel_callback(self, msg):\n        """Process velocity commands"""\n        self.cmd_twist = msg\n        # Apply limits to make it more realistic for humanoid\n        self.linear_velocity = max(-0.3, min(0.3, msg.linear.x))\n        self.angular_velocity = max(-0.5, min(0.5, msg.angular.z))\n\n    def update_robot_dynamics(self, dt):\n        """Update robot position and orientation based on commands"""\n        # Get current yaw from orientation quaternion\n        current_yaw = math.atan2(\n            2 * (self.orientation[3] * self.orientation[2] + self.orientation[0] * self.orientation[1]),\n            1 - 2 * (self.orientation[1]**2 + self.orientation[2]**2)\n        )\n\n        # Update orientation based on angular velocity\n        new_yaw = current_yaw + self.angular_velocity * dt\n        self.orientation[2] = math.sin(new_yaw / 2)\n        self.orientation[3] = math.cos(new_yaw / 2)\n\n        # Update position based on linear velocity and current orientation\n        dx = self.linear_velocity * math.cos(new_yaw) * dt\n        dy = self.linear_velocity * math.sin(new_yaw) * dt\n\n        self.position[0] += dx\n        self.position[1] += dy\n\n        # Simple balance model - the faster we move, the more we might lose balance\n        balance_change = self.linear_velocity * 0.1 + self.angular_velocity * 0.2\n        self.balance_state += balance_change * dt\n        self.balance_state *= self.balance_damping  # Apply damping\n        self.balance_state += np.random.normal(0, self.balance_noise)  # Add noise\n        self.balance_state = max(-1.0, min(1.0, self.balance_state))  # Clamp\n\n    def generate_laser_scan(self):\n        """Generate simulated laser scan data"""\n        num_points = 360\n        angle_min = -math.pi\n        angle_max = math.pi\n        angle_increment = (angle_max - angle_min) / num_points\n\n        ranges = []\n\n        for i in range(num_points):\n            angle = angle_min + i * angle_increment\n\n            # Calculate ray direction\n            ray_dir = np.array([math.cos(angle), math.sin(angle)])\n\n            # Find closest obstacle in this direction\n            min_range = 10.0  # Max range\n\n            for obstacle in self.obstacles:\n                # Vector from robot to obstacle\n                to_obstacle = obstacle[\'position\'] - self.position[:2]\n\n                # Calculate distance from ray to obstacle center\n                # Using ray-circle intersection\n                obstacle_distance = np.linalg.norm(to_obstacle)\n                obstacle_angle = math.atan2(to_obstacle[1], to_obstacle[0])\n\n                # Check if ray is pointing toward obstacle\n                angle_diff = abs(math.atan2(\n                    math.sin(angle - obstacle_angle),\n                    math.cos(angle - obstacle_angle)\n                ))\n\n                if angle_diff < 0.2:  # Within 0.2 rad of obstacle direction\n                    # Calculate closest approach\n                    closest_approach = abs(np.cross(to_obstacle, ray_dir))\n\n                    if closest_approach < obstacle[\'radius\']:\n                        # Ray intersects obstacle circle\n                        ray_to_center_proj = np.dot(to_obstacle, ray_dir)\n\n                        if ray_to_center_proj > 0:  # Obstacle is in front\n                            range_to_obstacle = ray_to_center_proj - math.sqrt(\n                                obstacle[\'radius\']**2 - closest_approach**2\n                            )\n\n                            if 0 < range_to_obstacle < min_range:\n                                min_range = range_to_obstacle\n\n            # Add some noise to make it more realistic\n            noise = np.random.normal(0, 0.02)\n            final_range = max(0.1, min_range + noise)\n            ranges.append(final_range)\n\n        scan_msg = LaserScan()\n        scan_msg.header.stamp = self.get_clock().now().to_msg()\n        scan_msg.header.frame_id = \'laser_frame\'\n        scan_msg.angle_min = angle_min\n        scan_msg.angle_max = angle_max\n        scan_msg.angle_increment = angle_increment\n        scan_msg.time_increment = 0.0\n        scan_msg.scan_time = 0.1\n        scan_msg.range_min = 0.1\n        scan_msg.range_max = 10.0\n        scan_msg.ranges = ranges\n\n        return scan_msg\n\n    def generate_imu_data(self):\n        """Generate simulated IMU data"""\n        imu_msg = Imu()\n        imu_msg.header.stamp = self.get_clock().now().to_msg()\n        imu_msg.header.frame_id = \'imu_frame\'\n\n        # Simulate orientation with some drift based on balance state\n        drift_x = self.balance_state * 0.1\n        drift_y = self.balance_state * 0.05\n\n        # Calculate orientation with drift\n        current_yaw = math.atan2(\n            2 * (self.orientation[3] * self.orientation[2] + self.orientation[0] * self.orientation[1]),\n            1 - 2 * (self.orientation[1]**2 + self.orientation[2]**2)\n        )\n\n        # Apply small drift based on balance state\n        corrected_yaw = current_yaw + drift_x\n\n        # Convert to quaternion\n        imu_msg.orientation.x = 0.0 + np.random.normal(0, 0.001)  # Small noise\n        imu_msg.orientation.y = drift_y + np.random.normal(0, 0.001)\n        imu_msg.orientation.z = math.sin(corrected_yaw / 2) + np.random.normal(0, 0.001)\n        imu_msg.orientation.w = math.cos(corrected_yaw / 2) + np.random.normal(0, 0.001)\n\n        # Angular velocity (simulated)\n        imu_msg.angular_velocity.x = np.random.normal(0, 0.01)\n        imu_msg.angular_velocity.y = np.random.normal(0, 0.01)\n        imu_msg.angular_velocity.z = self.angular_velocity + np.random.normal(0, 0.01)\n\n        # Linear acceleration (simulated gravity + movement)\n        imu_msg.linear_acceleration.x = self.linear_velocity * 0.1 + np.random.normal(0, 0.05)\n        imu_msg.linear_acceleration.y = np.random.normal(0, 0.05)\n        imu_msg.linear_acceleration.z = 9.81 + np.random.normal(0, 0.05)  # Gravity\n\n        return imu_msg\n\n    def simulation_step(self):\n        """Main simulation step"""\n        dt = 0.05  # 20 Hz\n        self.sim_time += dt\n\n        # Update robot dynamics\n        self.update_robot_dynamics(dt)\n\n        # Create and publish odometry\n        odom_msg = Odometry()\n        odom_msg.header.stamp = self.get_clock().now().to_msg()\n        odom_msg.header.frame_id = \'odom\'\n        odom_msg.child_frame_id = \'base_footprint\'\n\n        odom_msg.pose.pose.position.x = float(self.position[0])\n        odom_msg.pose.pose.position.y = float(self.position[1])\n        odom_msg.pose.pose.position.z = float(self.position[2])\n        odom_msg.pose.pose.orientation.x = float(self.orientation[0])\n        odom_msg.pose.pose.orientation.y = float(self.orientation[1])\n        odom_msg.pose.pose.orientation.z = float(self.orientation[2])\n        odom_msg.pose.pose.orientation.w = float(self.orientation[3])\n\n        # Set twist\n        odom_msg.twist.twist.linear.x = self.linear_velocity\n        odom_msg.twist.twist.angular.z = self.angular_velocity\n\n        self.odom_pub.publish(odom_msg)\n\n        # Broadcast transform\n        t = TransformStamped()\n        t.header.stamp = self.get_clock().now().to_msg()\n        t.header.frame_id = \'odom\'\n        t.child_frame_id = \'base_footprint\'\n        t.transform.translation.x = float(self.position[0])\n        t.transform.translation.y = float(self.position[1])\n        t.transform.translation.z = float(self.position[2])\n        t.transform.rotation.x = float(self.orientation[0])\n        t.transform.rotation.y = float(self.orientation[1])\n        t.transform.rotation.z = float(self.orientation[2])\n        t.transform.rotation.w = float(self.orientation[3])\n        self.tf_broadcaster.sendTransform(t)\n\n    def publish_sensors(self):\n        """Publish sensor data"""\n        scan_msg = self.generate_laser_scan()\n        self.scan_pub.publish(scan_msg)\n\n        imu_msg = self.generate_imu_data()\n        self.imu_pub.publish(imu_msg)\n\n        # Publish status\n        status_msg = String()\n        status_msg.data = f"Pos: ({self.position[0]:.2f}, {self.position[1]:.2f}), " \\\n                         f"Vel: ({self.linear_velocity:.2f}, {self.angular_velocity:.2f}), " \\\n                         f"Balance: {self.balance_state:.2f}, Cmd: ({self.cmd_twist.linear.x:.2f}, {self.cmd_twist.angular.z:.2f})"\n        self.status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    simulator = HumanoidNavigationSimulator()\n\n    try:\n        rclpy.spin(simulator)\n    except KeyboardInterrupt:\n        simulator.get_logger().info("Humanoid Navigation Simulator stopped by user")\n    finally:\n        simulator.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"quick-recap",children:"Quick Recap"}),"\n",(0,o.jsx)(e.p,{children:"In this lesson, we've covered:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Nav2 Configuration"}),": Adapting Nav2 parameters for humanoid robot kinematics and safety requirements"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Custom Path Planning"}),": Implementing balance-aware path planning with ZMP (Zero Moment Point) considerations"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Humanoid Controllers"}),": Creating controllers that respect bipedal locomotion constraints"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Balance Integration"}),": Incorporating balance and stability metrics into navigation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Simulation Environment"}),": Demonstrating the complete navigation system in simulation"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"The Nav2 framework can be successfully adapted for humanoid robots by considering their unique constraints: balance requirements, limited support polygon, and complex locomotion patterns. The key is to modify both the planning and control layers to account for the robot's bipedal nature and stability requirements."}),"\n",(0,o.jsx)(e.h2,{id:"summary-of-chapter-4",children:"Summary of Chapter 4"}),"\n",(0,o.jsx)(e.p,{children:'In Chapter 4: "The AI-Robot Brain (NVIDIA Isaac)", we\'ve covered:'}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Introduction to NVIDIA Isaac Sim"}),": Core concepts and capabilities of the Isaac Sim platform"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Synthetic Data Generation"}),": Creating diverse, labeled datasets for AI training with domain randomization"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac ROS for VSLAM"}),": Implementing visual SLAM systems with Isaac ROS packages"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Nav2 Path Planning for Humanoid Robots"}),": Adapting navigation for complex bipedal robots"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"This chapter has provided a comprehensive overview of how AI techniques, particularly those enabled by NVIDIA's Isaac platform, can enhance robotic perception, mapping, and navigation capabilities."})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(c,{...n})}):c(n)}},8453(n,e,a){a.d(e,{R:()=>i,x:()=>r});var t=a(6540);const o={},s=t.createContext(o);function i(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:i(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);